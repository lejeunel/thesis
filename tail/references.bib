@INPROCEEDINGS{chang13,
author={J. Chang and D. Wei and J. W. Fisher},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
title={A Video Representation Using Temporal Superpixels},
year={2013},
pages={2051-2058}
}

@book{hastie09,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@article{sermanet13,
  title={Overfeat: Integrated recognition, localization and detection using convolutional networks},
  author={Sermanet, Pierre and Eigen, David and Zhang, Xiang and Mathieu, Micha{\"e}l and Fergus, Rob and LeCun, Yann},
  journal={arXiv preprint arXiv:1312.6229},
  year={2013}
}

@inproceedings{zhou04,
  title={Learning with local and global consistency},
  author={Zhou, Dengyong and Bousquet, Olivier and Lal, Thomas N and Weston, Jason and Sch{\"o}lkopf, Bernhard},
  booktitle={Advances in neural information processing systems},
  pages={321--328},
  year={2004}
}


@misc{BRATSChall,
title = {{BRATS Challenge}},
howpublished = {http://braintumorsegmentation.org}
}


@article{achanta12,
 author = {Achanta, Radhakrishna and Shaji, Appu and Smith, Kevin and Lucchi, Aurelien and Fua, Pascal and Susstrunk, Sabine},
 title = {SLIC Superpixels Compared to State-of-the-Art Superpixel Methods},
 journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
 issue_date = {November 2012},
 volume = {34},
 number = {11},
 month = nov,
 year = {2012},
 issn = {0162-8828},
 pages = {2274--2282},
 numpages = {9},
 url = {http://dx.doi.org/10.1109/TPAMI.2012.120},
 doi = {10.1109/TPAMI.2012.120},
 acmid = {2377556},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {Superpixels, segmentation, clustering, k-means},
}

@article{zhang15,
abstract = {Due to the rapid technological development of various different satellite sensors, a huge volume of high-resolution image data sets can now be acquired. How to efficiently represent and recognize the scenes from such high-resolution image data has become a critical task. In this paper, we propose an unsupervised feature learning framework for scene classification. By using the saliency detection algorithm, we extract a representative set of patches from the salient regions in the image data set. These unlabeled data patches are exploited by an unsupervised feature learning method to learn a set of feature extractors which are robust and efficient and do not need elaborately designed descriptors such as the scale-invariant-feature-transform-based algorithm. We show that the statistics generated from the learned feature extractors can characterize a complex scene very well and can produce excellent classification accuracy. In order to reduce overfitting in the feature learning step, we further employ a recently developed regularization method called 'dropout,' which has proved to be very effective in image classification. In the experiments, the proposed method was applied to two challenging high-resolution data sets: the UC Merced data set containing 21 different aerial scene categories with a submeter resolution and the Sydney data set containing seven land-use categories with a 60-cm spatial resolution. The proposed method obtained results that were equal to or even better than the previous best results with the UC Merced data set, and it also obtained the highest accuracy with the Sydney data set, demonstrating that the proposed unsupervised-feature-learning-based scene classification method provides more accurate classification results than the other latent-Dirichlet-allocation-based methods and the sparse coding method.},
author = {Zhang, Fan and Du, Bo and Zhang, Liangpei},
doi = {10.1109/TGRS.2014.2357078},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Du, Zhang - 2015 - Saliency-Guided Unsupervised Feature Learning for Scene Classification(2).pdf:pdf},
isbn = {0196-2892},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Autoencoder,saliency detection,scene classification,unsupervised feature learning},
number = {4},
pages = {2175--2184},
title = {{Saliency-guided unsupervised feature learning for scene classification}},
url = {http://ieeexplore.ieee.org/ielx7/36/6919366/06910306.pdf?tp={\&}arnumber=6910306{\&}isnumber=6919366},
volume = {53},
year = {2015}
}

@article{cheriyadat14,
abstract = {The rich data provided by high-resolution satellite imagery allow us to directly model aerial scenes by understanding their spatial and structural patterns. While pixel- and object-based classification approaches are widely used for satellite image analysis, often these approaches exploit the high-fidelity image data in a limited way. In this paper, we explore an unsupervised feature learning approach for scene classification. Dense low-level feature descriptors are extracted to characterize the local spatial patterns. These unlabeled feature measurements are exploited in a novel way to learn a set of basis functions. The low-level feature descriptors are encoded in terms of the basis functions to generate new sparse representation for the feature descriptors. We show that the statistics generated from the sparse features characterize the scene well producing excellent classification accuracy. We apply our technique to several challenging aerial scene data sets: ORNL-I data set consisting of 1-m spatial resolution satellite imagery with diverse sensor and scene characteristics representing five land-use categories, UCMERCED data set representing twenty one different aerial scene categories with sub-meter resolution, and ORNL-II data set for large-facility scene detection. Our results are highly promising and, on the UCMERCED data set we outperform the previous best results. We demonstrate that the proposed aerial scene classification method can be highly effective in developing a detection system that can be used to automatically scan large-scale high-resolution satellite imagery for detecting large facilities such as a shopping mall.},
author = {Cheriyadat, Anil M},
doi = {10.1109/TGRS.2013.2241444},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheriyadat - 2014 - Unsupervised Feature Learning for Aerial Scene Classification(2).pdf:pdf},
isbn = {0196-2892},
issn = {0196-2892},
journal = {Geoscience and Remote Sensing, IEEE Transactions on},
keywords = {Aerial data,Encoding,Histograms,Kernel,ORNL-II data set,Support vector machines,UCMERCED data set,Vectors,Visualization,aerial scene classification,aerial scene data sets,basis function,classification,codebook,dense low-level feature,dictionary,feature extraction,feature learning,geophysical image processing,geophysical techniques,high-fidelity image data,high-resolution satellite imagery,image classification,object-based classification,pixel-based classification,remote sensing,satellite image analysis,sparse coding,unsupervised feature learning},
number = {1},
pages = {439--451},
title = {{Unsupervised Feature Learning for Aerial Scene Classification}},
url = {http://ieeexplore.ieee.org/ielx7/36/6675822/06472060.pdf?tp={\&}arnumber=6472060{\&}isnumber=6675822 http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6472060},
volume = {52},
year = {2014}
}
@misc{openCV,
  title={Open Source Computer Vision Library},
  author={Itseez},
  year={2015},
  howpublished = {\url{https://github.com/itseez/opencv}}
}


@Misc{scipy,
  author =    {Eric Jones and Travis Oliphant and Pearu Peterson and others},
  title =     {{SciPy}: Open source scientific tools for {Python}},
  year =      {2001--},
  url = "http://www.scipy.org/"
}

@inproceedings{yang09,
abstract = {Recently SVMs using spatial pyramid matching (SPM) kernel have been highly successful in image classification. Despite its popularity, these nonlinear SVMs have a com-plexity O(n 2 ∼ n 3) in training and O(n) in testing, where n is the training size, implying that it is nontrivial to scale-up the algorithms to handle more than thousands of training images. In this paper we develop an extension of the SPM method, by generalizing vector quantization to sparse cod-ing followed by multi-scale spatial max pooling, and pro-pose a linear SPM kernel based on SIFT sparse codes. This new approach remarkably reduces the complexity of SVMs to O(n) in training and a constant in testing. In a num-ber of image categorization experiments, we find that, in terms of classification accuracy, the suggested linear SPM based on sparse coding of SIFT descriptors always signif-icantly outperforms the linear SPM kernel on histograms, and is even better than the nonlinear SPM kernels, leading to state-of-the-art performance on several benchmarks by using a single type of descriptors.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1504.06897},
author = {Yang, Jianchao and Yu, Kai and Gong, Yihong and Beckman, Thomas Huang},
booktitle = {IEEE Compmuter Society Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2009.5206757},
eprint = {1504.06897},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2009 - Linear Spatial Pyramid Matching Using Sparse Coding for Image Classification.pdf:pdf},
isbn = {1063-6919 VO -},
issn = {1063-6919},
pages = {1794--1801},
title = {{Linear Spatial Pyramid Matching Using Sparse Coding for Image Classification}},
year = {2009}
}

@article{lazebnik09,
abstract = {The present paper reports about an immunocytochemical inventory of the cell types involved in the metabolic activation of the tobacco-specific nitrosamine 4-(methylnitrosamino)-1-(3-pyridyl)-1-butanone (NNK) to a DNA methylating metabolite. The formation and distribution of the methylated DNA bases O6-methylguanine (O6-meGua) and 7-methylguanine (7-MeGua) were studied in respiratory tissues, oesophagus, liver, kidneys, pancreas, small intestine, colon and prostate of rat, mouse and hamster 6 h after treatment with a single dose of 30 mg NNK/kg. The tissue- and cell-specific distribution of O6-meGua- and 7-meGua-specific nuclear staining showed the same patterns and were remarkably similar in rat, mouse and hamster in spite of the diverging spectra of NNK-induced tumours in these species. In nasal tissue, a target for NNK-induced tumourigenesis in rat and hamster, but not in mouse, adduct-specific nuclear staining was observed in all three species in sustentacular cells, Bowman glands, respiratory epithelial cells and serous glands. Both methylated DNA bases were also observed in basal cells of the olfactory epithelium of rat and (occasionally) hamster, but not in those of the mouse. In the trachea, a target for NNK-induced tumourigenesis in hamster only, substantial adduct-specific nuclear staining was found in basal epithelial and glandular cells of the hamster; in the same cells of rat and mouse only a weak nuclear staining was found. In the lung, a common target for NNK-induced tumourigenesis, the formation of O6-meGua and 7-meGua was restricted predominantly to bronchial and proximal bronchiolar epithelium. Nuclear staining in the rat was occasionally found in alveolar cells and was also observed in hepatocytes. In the three species investigated, O6-meGua- and 7-MeGua-specific nuclear staining was found in target and non-target tissues. Apparently, and in analogy with results obtained in other studies, the species-specific organotropy for tumour formation of NNK is not exclusively determined by DNA methylation. Expanding methylation data with literature data on factors considered to be involved in tumour formation, namely proliferation, toxicity and DNA repair among others, still did not lead to a satisfactory explanation for the species-specific organotropy observed. Additional factors (yet to be identified), need to be taken into account in order to explain (and predict) tumourigenic effects induced by monofunctional methylating agents.},
archivePrefix = {arXiv},
arxivId = {1406.4729},
author = {Lazebnik, Svetlana},
doi = {10.1109/TPAMI.2015.2389824},
eprint = {1406.4729},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lazebnik et al. - Unknown - Spatial Pyramid Matching(2).pdf:pdf},
isbn = {978-3-319-10577-2},
issn = {01433334},
journal = {Object Categorization: Computer and Human Vision Perspectives},
number = {4},
pmid = {7522985},
title = {{Spatial pyramid matching}},
url = {https://pdfs.semanticscholar.org/ba8e/0bda11af08b6037666b67cf54ae1f780822d.pdf http://hal.inria.fr/docs/00/54/86/47/PDF/pyramid{\_}chapter.pdf},
volume = {3},
year = {2009}
}

@article{simonyan15,
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {1409.1556},
author = {Simonyan, Karen and Zisserman, Andrew},
doi = {10.1016/j.infsof.2008.09.005},
eprint = {1409.1556},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Simonyan, Zisserman - 2015 - VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION.pdf:pdf},
isbn = {9781450341448},
issn = {09505849},
journal = {International Conference on Learning Representations},
keywords = {()},
pmid = {16873662},
title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
url = {https://arxiv.org/pdf/1409.1556.pdf http://arxiv.org/abs/1409.1556},
year = {2015}
}

@article{long15,
abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20{\%} relative improvement to 62.2{\%} mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1411.4038},
author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
doi = {10.1109/CVPR.2015.7298965},
eprint = {1411.4038},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Long, Shelhamer, Darrell - 2015 - Fully Convolutional Networks for Semantic Segmentation ppt.pdf:pdf},
isbn = {9781467369640},
issn = {10636919},
journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
pages = {3431--3440},
pmid = {16190471},
title = {{Fully Convolutional Networks for Semantic Segmentation ppt}},
year = {2015}
}
@article{ng15,
abstract = {This paper presents the techniques employed in our team's submissions to the 2015 Emotion Recognition in the Wild contest, for the sub-challenge of Static Facial Expression Recognition in the Wild. The objective of this sub-challenge is to classify the emotions expressed by the primary human subject in static images extracted from movies. We follow a transfer learning approach for deep Convolutional Neural Network (CNN) architectures. Starting from a network pre-trained on the generic ImageNet dataset, we perform supervised fine-tuning on the network in a two-stage process, first on datasets relevant to facial expressions, followed by the contest's dataset. Experimental results show that this cascading fine-tuning approach achieves better results, compared to a single stage fine-tuning with the combined datasets. Our best submission exhibited an overall accuracy of 48.5{\%} in the validation set and 55.6{\%} in the test set, which compares favorably to the respective 35.96{\%} and 39.13{\%} of the challenge baseline.},
author = {Ng, Hong-Wei and Nguyen, Viet Dung and Vonikakis, Vassilios and Winkler, Stefan},
doi = {10.1145/2818346.2830593},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng et al. - Unknown - Deep Learning for Emotion Recognition on Small Datasets Using Transfer Learning.pdf:pdf},
isbn = {9781450339124},
journal = {Proceedings of the 2015 ACM on International Conference on Multimodal Interaction - ICMI '15},
keywords = {deep learning,emotion classification,facial expression analysis},
pages = {443--449},
title = {{Deep Learning for Emotion Recognition on Small Datasets using Transfer Learning}},
url = {http://delivery.acm.org/10.1145/2840000/2830593/p443-ng.pdf?ip=130.92.9.58{\&}id=2830593{\&}acc=ACTIVE SERVICE{\&}key=FC66C24E42F07228.E8874AA355AB3480.4D4702B0C3E38B35.4D4702B0C3E38B35{\&}CFID=794628962{\&}CFTOKEN=13543468{\&}{\_}{\_}acm{\_}{\_}=1502261037{\_}034a078094d1f06739665bacb69},
year = {2015}
}

@article{ILSVRC15,
  Author={Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  Title={{ImageNet Large Scale Visual Recognition Challenge}},
  Year={2015},
  journal={International Journal of Computer Vision (IJCV)},
  doi={10.1007/s11263-015-0816-y},
  volume={115},
  number={3},
  pages={211-252}
}

@misc{simonyan14a,
author = {Simonyan, Karen and Zisserman, Andrew},
title = {{Visual Geometry Group Home Page}},
url = {http://www.robots.ox.ac.uk/{~}vgg/research/very{\_}deep/},
urldate = {2017-08-09},
year = {2014}
}

@phdthesis{imdescrip,
 title={An Unsupervised Approach to Modelling Visual Data},
 author={Steinberg, D. M.},
 year={2013}
}

@article{pan2010,
author={S. J. Pan and Q. Yang},
journal={IEEE Transactions on Knowledge and Data Engineering},
title={A Survey on Transfer Learning},
year={2010},
volume={22},
number={10},
pages={1345-1359},
keywords={knowledge engineering;learning by example;optimisation;unsupervised learning;data mining;inductive transfer learning;knowledge transfer;machine learning;transductive transfer learning;unsupervised transfer learning;Data mining;Knowledge engineering;Knowledge transfer;Labeling;Learning systems;Machine learning;Machine learning algorithms;Space technology;Testing;Training data;Transfer learning;data mining.;machine learning;survey},
doi={10.1109/TKDE.2009.191},
ISSN={1041-4347},
month={Oct},}

@article{vorontsov17,
abstract = {We propose a model for the joint segmentation of the liver and liver lesions in computed tomography (CT) volumes. We build the model from two fully convolutional networks con-nected in tandem and trained together end-to-end. The first network is trained to produce a representation that is used for liver segmentation. This representation is passed to ev-ery layer in the second network, the output of which is used to produce a lesion segmentation. We evaluate the approach on the 2017 ISBI Liver Tumour Segmentation Challenge and place second with a per-volume average Dice score of 0.65.},
author = {Vorontsov, Eugene and Chartrand, Gabriel and Tang, An and Pal, Chris and Kadoury, Samuel},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vorontsov et al. - Unknown - LIVER LESION SEGMENTATION INFORMED BY JOINT LIVER SEGMENTATION(2).pdf:pdf},
journal = {arXiv preprint arXiv:1707.07734},
keywords = {Index Terms— segmentation,neural network},
title = {{Liver lesion segmentation informed by joint liver segmentation}},
url = {https://arxiv.org/pdf/1707.07734.pdf https://arxiv.org/pdf/1707.07734v1.pdf},
year = {2017}
}

@article{gastaldi17,
   author = {{Gastaldi}, X.},
    title = "{Shake-Shake regularization}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1705.07485},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Computer Science - Computer Vision and Pattern Recognition},
     year = 2017,
    month = may,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170507485G},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{kurmann17,
author = {Kurmann, Thomas and Neila, Pablo Marquez and Du, Xiaofei and Fua, Pascal and Wolf, Sebastian and Sznitman, Raphael},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kurmann et al. - 2017 - Simultaneous Recognition and Pose Estimation of Instruments in Minimally Invasive Surgery.pdf:pdf},
journal = {MICCAI 2017, Part II, LNCS 10434 proceedings},
title = {{Simultaneous Recognition and Pose Estimation of Instruments in Minimally Invasive Surgery}},
year = {2017}
}

@inproceedings{lea16,
abstract = {Joint segmentation and classification of fine-grained actions is important for applications of human-robot interaction, video surveil-lance, and human skill evaluation. However, despite substantial recent progress in large-scale action classification, the performance of state-of-the-art fine-grained action recognition approaches remains low. We propose a model for action segmentation which combines low-level spa-tiotemporal features with a high-level segmental classifier. Our spatiotem-poral CNN is comprised of a spatial component that uses convolutional filters to capture information about objects and their relationships, and a temporal component that uses large 1D convolutional filters to capture information about how object relationships change across time. These features are used in tandem with a semi-Markov model that models tran-sitions from one action to another. We introduce an efficient constrained segmental inference algorithm for this model that is orders of magnitude faster than the current approach. We highlight the effectiveness of our Segmental Spatiotemporal CNN on cooking and surgical action datasets for which we observe substantially improved performance relative to re-cent baseline methods.},
author = {Lea, Colin and Reiter, Austin and Vidal, Ren{\'{e}} and Hager, Gregory D},
booktitle = {European Conference on Computer Vision},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lea et al. - Unknown - Segmental Spatiotemporal CNNs for Fine-grained Action Segmentation.pdf:pdf},
pages = {36--52},
title = {{Segmental Spatiotemporal CNNs for Fine-grained Action Segmentation}},
url = {https://arxiv.org/pdf/1602.02995.pdf},
year = {2016}
}

@inproceedings{shi15,
abstract = {The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the ma-chine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting prob-lem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.},
author = {Shi, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-Kin and Woo, Wang-Chun},
booktitle = {Advances in neural information processing systems},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shi et al. - Unknown - Convolutional LSTM Network A Machine Learning Approach for Precipitation Nowcasting.pdf:pdf},
pages = {802--810},
title = {{Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting}},
url = {https://arxiv.org/pdf/1506.04214.pdf},
year = {2015}
}

@article{segal04,
abstract = {Breiman (2001a,b) has recently developed an ensemble classification and regression approach that displayed outstanding performance with regard prediction error on a suite of benchmark datasets. As the base constituents of the ensemble are tree-structured predictors, and since each of these is constructed using an injection of randomness, the method is called random forests. That the exceptional performance is attained with seemingly only a single tuning parameter, to which sensitivity is minimal, makes the methodology all the more remarkable. The individual trees comprising the forest are all grown to maximal depth. While this helps with regard bias, there is the familiar tradeoff with variance. However, these variability concerns were potentially obscured because of an interesting feature of those benchmarking datasets extracted from the UCI machine learning repository for testing: all these datasets are hard to overfit using tree-structured methods. This raises issues about the scope of the repository. With this as motivation, and coupled with experience from boosting methods, we revisit the formulation of random forests and investigate prediction performance on real-world and simulated datasets for which maximally sized trees do overfit. These explorations reveal that gains can be realized by additional tuning to regulate tree size via limiting the number of splits and/or the size of nodes for which splitting is allowed. Nonetheless, even in these settings, good performance for random forests can be attained by using larger (than default) primary tuning parameter values.},
author = {Segal, Mark R},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Segal - 2003 - Machine Learning Benchmarks and Random Forest Regression(2).pdf:pdf},
journal = {Biostatistics},
keywords = {prediction error,regression,uci repository},
number = {MAY 2003},
pages = {1--14},
title = {{Machine Learning Benchmarks and Random Forest Regression}},
url = {http://www.biostat.ucsf.edu/cbmb/publications/bench.rf.regn.pdf http://escholarship.org/uc/item/35x3v9t4.pdf},
year = {2004}
}

@article{davis06,
abstract = {Receiver Operator Characteristic (ROC) curves are commonly used to present results for binary decision problems in machine learning. However, when dealing with highly skewed datasets, Precision-Recall (PR) curves give a more informative picture of an algorithm's performance. We show that a deep connection exists between ROC space and PR space, such that a curve dominates in ROC space if and only if it dominates in PR space. A corollary is the notion of an achievable PR curve, which has properties much like the convex hull in ROC space; we show an efficient algorithm for computing this curve. Finally, we also note differences in the two types of curves are significant for algorithm design. For example, in PR space it is incorrect to linearly interpolate between points. Furthermore, algorithms that optimize the area under the ROC curve are not guaranteed to optimize the area under the PR curve.},
archivePrefix = {arXiv},
arxivId = {1609.07195},
author = {Davis, Jesse and Goadrich, Mark},
doi = {10.1145/1143844.1143874},
eprint = {1609.07195},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davis, Goadrich - Unknown - The Relationship Between Precision-Recall and ROC Curves(2).pdf:pdf},
isbn = {1595933832},
issn = {14710080},
journal = {Proceedings of the 23rd International Conference on Machine learning -- ICML'06},
pages = {233--240},
pmid = {19165215},
title = {{The Relationship Between Precision-Recall and ROC Curves}},
url = {http://delivery.acm.org/10.1145/1150000/1143874/p233-davis.pdf?ip=130.92.9.58{\&}id=1143874{\&}acc=ACTIVE SERVICE{\&}key=FC66C24E42F07228.E8874AA355AB3480.4D4702B0C3E38B35.4D4702B0C3E38B35{\&}CFID=797614004{\&}CFTOKEN=26964052{\&}{\_}{\_}acm{\_}{\_}=1502776330{\_}10afdf8c3302f92aa92cf52d},
year = {2006}
}

@inproceedings{csillik16,
           month = {September},
           title = {Superpixels: the end of pixels in OBIA. A comparison of stat-of-the-art superpixel methods for remote sensing data},
          author = {O. {Csillik}},
            year = {2016},
             url = {http://proceedings.utwente.nl/439/},
        abstract = {In computer vision, using superpixels or perceptually meaningful atomic regions to speed up later-stage processing are becoming increasingly popular in many applications. Superpixels are used as a pre-processing stage to organize an image into a low-level grouping process through oversegmentation, thus simplifying the computation in later stages. However, in remote sensing domain few studies use superpixels. Even so, there is no comparison between superpixel methods and their suitability for remote sensing images. In this study, we compare four state-of-the-art superpixel methods: Simple Linear Iterative Clustering (SLIC and SLICO), Superpixels Extracted via Energy-Driven Sampling (SEEDS) and Linear Spectral Clustering (LSC). We applied them to very high resolution remote sensing data of different characteristics (extent, spatial resolution and landscape complexity) in order to see how superpixels are affected by these factors. The four algorithms were compared regarding their computational time, ability to adhere to image boundaries and the accuracy of the resulted superpixels. Furthermore, we discuss the individual strengths and weaknesses of each algorithm and draw further applications of superpixels in OBIA.}
}

@inproceedings{kingma15,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order mo-ments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpre-tations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical con-vergence properties of the algorithm and provide a regret bound on the conver-gence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
author = {Kingma, Diederik P and Adam, Jimmy Ba},
booktitle = {International Conference on Learning Representation},
doi = {10.1109/ICCCBDA.2017.7951902},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kingma, Ba - Unknown - ADAM A METHOD FOR STOCHASTIC OPTIMIZATION(2).pdf:pdf},
isbn = {9781509044986},
title = {{A method for stochastic optimization}},
url = {https://arxiv.org/pdf/1412.6980.pdf},
year = {2015}
}

@article{glorot10,
abstract = {Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We ﬁrst observe the inﬂuence of the non-linear activations functions. We ﬁnd that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we ﬁnd that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We ﬁnd that a new non-linearity that saturates less can often be beneﬁcial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difﬁcult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.},
author = {Glorot, Xavier and Bengio, Yoshua},
doi = {10.1.1.207.2059},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Glorot, Bengio - Unknown - Understanding the difficulty of training deep feedforward neural networks.pdf:pdf},
isbn = {9781937284275},
issn = {15324435},
journal = {Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {249--256},
title = {{Understanding the difficulty of training deep feedforward neural networks}},
url = {http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf http://machinelearning.wustl.edu/mlpapers/paper{\_}files/AISTATS2010{\_}GlorotB10.pdf},
volume = {9},
year = {2010}
}

@article{huynh16,
  title={Digital mammographic tumor classification using transfer learning from deep convolutional neural networks},
  author={Huynh, Benjamin Q and Li, Hui and Giger, Maryellen L},
  journal={Journal of Medical Imaging},
  volume={3},
  number={3},
  pages={034501},
  year={2016},
  publisher={International Society for Optics and Photonics}
}

@book{goodfellow16,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{mcculloch43,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  number={4},
  pages={115--133},
  year={1943},
  publisher={Springer}
}

@article{lecun95,
  title={Convolutional networks for images, speech, and time series},
  author={LeCun, Yann and Bengio, Yoshua and others},
  journal={The handbook of brain theory and neural networks},
  volume={3361},
  number={10},
  pages={1995},
  year={1995}
}

@article{lejeune18,
  title={Iterative multi-path tracking for video and volume segmentation with sparse point supervision},
  author={Lejeune, Laurent and Grossrieder, Jan and Sznitman, Raphael},
  journal={Medical image analysis},
  volume={50},
  pages={65--81},
  year={2018},
  publisher={Elsevier}
}

@article{ioffe15,
  author    = {Sergey Ioffe and
               Christian Szegedy},
  title     = {Batch Normalization: Accelerating Deep Network Training by Reducing
               Internal Covariate Shift},
  journal   = {CoRR},
  volume    = {abs/1502.03167},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.03167},
  archivePrefix = {arXiv},
  eprint    = {1502.03167},
  timestamp = {Mon, 13 Aug 2018 16:47:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/IoffeS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kingma14,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{tieleman12,
  title={Lecture 6.5-rmsprop, coursera: Neural networks for machine learning},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={University of Toronto, Technical Report},
  year={2012}
}

@article{he15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on
               ImageNet Classification},
  journal   = {CoRR},
  volume    = {abs/1502.01852},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.01852},
  archivePrefix = {arXiv},
  eprint    = {1502.01852},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZR015.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@INPROCEEDINGS{yun13,
author={K. Yun and Y. Peng and D. Samaras and G. J. Zelinsky and T. L. Berg},
booktitle={CVPR},
title={Studying Relationships between Human Gaze, Description, and Computer Vision},
year={2013},
pages={739-746},
}

@inproceedings{KonSznFua15,
  author    = {Konyushkova, Ksenia  and Sznitman, Raphael and Fua, Pascal},
  title     = {Introducing Geometry in Active Learning for Image Segmentation},
  booktitle   = {Internationl Conference on Computer Vision},
  year      = {2015},
  pages ={2974--2982}
}

@inproceedings{Cheplygina2016,
author="Cheplygina, Veronika
and Perez-Rovira, Adria
and Kuo, Wieying
and Tiddens, Harm A. W. M.
and de Bruijne, Marleen",
title="Early Experiences with Crowdsourcing Airway Annotations in Chest CT",
bookTitle=" LABELS Workshop, MICCAI",
year="2016",
pages="209--218",
}

@inproceedings{Li2005,
author = {Li, Xiao-Li and Liu, Bing},
booktitle = {European Conference on Machine Learning},
pages = {218--229},
title = {{Learning from Positive and Unlabeled Examples with Different Data Distributions}},
year = {2005}
}

@incollection{Guyon17,
title = {Online Learning with Transductive Regret},
author = {Yang, Scott and Mohri, Mehryar},
booktitle = {Advances in Neural Information Processing Systems},
pages = {5220--5230},
year = {2017},
publisher={NOPUBLISHER}
}

@incollection{Burges13,
title = {Transfer Learning in a Transductive Setting},
author = {Rohrbach, Marcus and Ebert, Sandra and Schiele, Bernt},
booktitle = {Advances in Neural Information Processing Systems 26},
pages = {46--54},
year = {2013},
publisher={NOPUBLISHER}
}


@inproceedings{Kiryo2017,
author = {Kiryo, Ryuichi and Niu, Gang and {Du Plessis}, Marthinus C and Sugiyama, Masashi},
booktitle = {Neural Information Processing Systems },
title = {{Positive-Unlabeled Learning with Non-Negative Risk Estimator}},
year = {2017},
pages = {NOPAGES},
}


@article{koch98,
author = {Itti, L and Koch, C and Niebur, E},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {11},
pages = {1254--1259},
title = {{A Model of Saliency-Based Visual Attention for Rapid Scene Analysis}},
volume = {20},
year = {1998}
}


@inproceedings{MaierHein2014,
author="Maier-Hein, Lena
and Mersmann, Sven
and Kondermann, Daniel
and Bodenstedt, Sebastian
and Sanchez, Alexandro
and Stock, Christian
and Kenngott, Hannes Gotz
and Eisenmann, Mathias
and Speidel, Stefanie",
title="Can Masses of Non-Experts Train Highly Accurate Image Classifiers?",
bookTitle="MICCAI",
year="2014",
pages="438--445",
}

@article{menze15,
  TITLE = {{The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)}},
  AUTHOR = {Menze, Bjoern {et. al.}.},
  JOURNAL = {{IEEE Transactions on Medical Imaging}},
  VOLUME = {34},
  NUMBER = {10},
  PAGES = {1993--2024},
  YEAR = {2014},
}


@inproceedings{vilarino07,
author="Vilari{\~{n}}o, Fernando
and Lacey, Gerard
and Zhou, Jiang
and Mulcahy, Hugh
and Patchett, Stephen",
title="Automatic Labeling of Colonoscopy Video for Cancer Detection",
bookTitle="Iberian Conference on Pattern Recognition and Image Analysis",
year="2007",
pages="290--297",
}

@Article{vandenbergh2014,
  author = {Michael Van den Bergh and Xavier Boix and Gemma Roig and Luc Van Gool },
  title = {SEEDS: Superpixels Extracted Via Energy-Driven Sampling},
  journal = {International Journal of Computer Vision},
  year = {2014},
  month = {},
  pages = {},
  volume = {},
  number = {},
  keywords = {},
  note = {in press}
}

@InProceedings{mettes16,
author="Mettes, Pascal
and van Gemert, Jan C.
and Snoek, Cees G. M.",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="Spot On: Action Localization from Pointly-Supervised Proposals",
booktitle="European Conference on Computer Vision ",
year="2016",
pages="437--453",
}

@inproceedings{sadegh09,
 author    = {Sadeghi, M. and Tien, G. and Hamarneh, G. and Atkins, M. S.},
 title     = {Hands-free interactive image segmentation using eyegaze},
 booktitle = {Proceedings SPIE, Medical Imaging Computer-Aided Diagnosis},
 year      = {2009},
 pages     = {7260}
}

@INPROCEEDINGS{Papadopoulos17,
author={D. P. Papadopoulos and J. R. R. Uijlings and F. Keller and V. Ferrari},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
title={Training Object Class Detectors with Click Supervision},
year={2017},
pages={180-189},
month={July}
}


@inproceedings{MosSzn16,
author = {Mosinska-Domanska, Agata and Sznitman, Raphael and Glowacki, Przemyslaw and Fua, Pascal},
title = {Active Learning for Delineation of Curvilinear Structures},
booktitle = {CVPR},
year = {2016},
pages = {5231--5239}
}

@inproceedings{BerBecSalFua2016,
author={Berm{\'u}dez-Chac{\'o}n, R{\'o}ger and Becker, Carlos and Salzmann, Mathieu and Fua, Pascal},
title     ={Scalable Unsupervised Domain Adaptation for Electron Microscopy},
bookTitle ={MICCAI},
year      ={2016},
pages     ={326--334},
}

@article{ShiRoth16,
  TITLE = {Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning},
  AUTHOR = {Shin, H. and Roth, H. and Gao, M. and Lu, L. and Xu, Z. and Nogues, I. and Yao, J. and Mollura, D. and Summers, R.},
  JOURNAL = {IEEE Transactions on Medical Imaging},
  VOLUME = {35},
  NUMBER = {5},
  PAGES = {1285--1298},
  YEAR = {2016},
}

@incollection{sznitman2014,
  title={Fast part-based classification for instrument detection in minimally invasive surgery},
  author={Sznitman, Raphael and Becker, Carlos and Fua, Pascal},
  booktitle={MICCAI},
  pages={692--699},
  year={2014},
  publisher={Springer}
}

@Article{franklin2008,
author="Franklin, James",
title="The elements of statistical learning: data mining, inference and prediction",
journal="The Mathematical Intelligencer",
year="2008",
volume="27",
number="2",
pages="83--85",
}

@article{boykov01,
  title={Fast approximate energy minimization via graph cuts},
  author={Boykov, Yuri and Veksler, Olga and Zabih, Ramin},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  volume={23},
  number={11},
  pages={1222--1239},
  year={2001},
  publisher={IEEE}
}


@ARTICLE{boykov2004,
author={Y. Boykov and V. Kolmogorov},
journal={IEEE Trans. Pattern Anal. Mach. Intell.},
title={An experimental comparison of min-cut/max- flow algorithms for energy minimization in vision},
year={2004},
volume={26},
number={9},
pages={1124-1137},
keywords={computational complexity;computer vision;directed graphs;image restoration;image segmentation;minimax techniques;stereo image processing;tree searching;Ford-Fulkerson style algorithms;Goldberg-Tarjan style methods;augmenting path algorithms;combinatorial optimization;computer vision;energy minimization;graph algorithms;image restoration;image segmentation;image stereo;low level vision;minimum cut-maximum flow algorithms;polynomial time complexity;push-relabel methods;Application software;Clustering algorithms;Computer vision;Image restoration;Image segmentation;Iterative algorithms;Labeling;Minimization methods;Simulated annealing;Stereo vision;Index Terms- Energy minimization;graph algorithms;image restoration;maximum flow;minimum cut;multicamera scene reconstruction.;segmentation;stereo;Algorithms;Artificial Intelligence;Cluster Analysis;Energy Transfer;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Pattern Recognition, Automated;Photogrammetry;Photography;Reproducibility of Results;Sensitivity and Specificity},
doi={10.1109/TPAMI.2004.60},
ISSN={0162-8828},
month={Sept},}

@book{bakir2007,
  title={Predicting structured data},
  author={Bakir, G{\"o}khan},
  year={2007},
  publisher={MIT press}
}


@ARTICLE{serradell2015,
author={E. Serradell and M. A. Pinheiro and R. Sznitman and J. Kybic and F. Moreno-Noguer and P. Fua},
journal={IEEE Trans. Pattern Anal. Mach. Intell.},
title={Non-Rigid Graph Registration Using Active Testing Search},
year={2015},
volume={37},
number={3},
pages={625-638},
keywords={Gaussian processes;Image resolution;Microscopy;Noise;Retina;Search problems;Testing;Graph matching;active testing search;non-rigid registration},
doi={10.1109/TPAMI.2014.2343235},
ISSN={0162-8828},
month={March},}

@ARTICLE{tsiligkaridis2014,
author={T. Tsiligkaridis and B. M. Sadler and A. O. Hero},
journal={IEEE Transactions on Information Theory},
title={Collaborative 20 Questions for Target Localization},
year={2014},
volume={60},
number={4},
pages={2233-2252},
keywords={entropy;error statistics;learning (artificial intelligence);mean square error methods;probability;target tracking;active machine learning;binary query;collaborative questions;convergence rates;entropy;error exponents;error probability;mean square error;multiple players;noisy response;optimal policy;probabilistic bisection;refined filtration;sequential policy;sequential scheme;stochastic search problems;target localization;target location;Collaboration;Entropy;Games;Joints;Noise measurement;Probabilistic logic;Search problems;Optimal query selection;convergence rate;human-aided decision making;machine–machine interaction;minimum entropy;target localization},
doi={10.1109/TIT.2014.2304455},
ISSN={0018-9448},
month={April},}

@incollection{duPlessis2014,
title = {Analysis of Learning from Positive and Unlabeled Data},
author = {du Plessis, Marthinus C and Niu, Gang and Sugiyama, Masashi},
booktitle = {Advances in Neural Information Processing Systems 27},
editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
pages = {703--711},
year = {2014},
}

@inproceedings{duPlessis2015,
   title="Convex Formulation for Learning from Positive and Unlabeled Data",
   Author={Plessis, Marthinus Du and Niu, Gang and Sugiyama, Masashi},
   year="2015",
   Booktitle="International Conference on Machine Learning",
   pages="1386 -- 1394"
   }

@INPROCEEDINGS{sznitman2013,
author={R. Sznitman and C. Becker and F. Fleuret and P. Fua},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
title={Fast Object Detection with Entropy-Driven Evaluation},
year={2013},
pages={3270-3277},
}

@article{saberian2014,
  author  = {Mohammad Saberian and Nuno Vasconcelos},
  title   = {Boosting Algorithms for Detector Cascade Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  pages   = {2569-2605},
}

@INPROCEEDINGS{bourdev2005,
author={L. Bourdev and J. Brandt},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
title={Robust object detection via soft cascade},
year={2005},
volume={2},
pages={236-243 vol. 2},
}

@incollection{zhang2007,
    Publisher = {MIT Press},
    Author = {Cha Zhang and Paul A. Viola},
    Booktitle = {Advances in Neural Information Processing Systems},
    Title = {Multiple-Instance Pruning For Learning Efficient Cascade Detectors},
    Year = {2007},
    Pages = {1681--1688}
   }

@INPROCEEDINGS{sochman2005,
author={J. Sochman and J. Matas},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
title={WaldBoost - learning for time constrained sequential detection},
year={2005},
volume={2},
pages={150-156},
}

@MISC{freund1999,
    author = {Yoav Freund and Robert E. Schapire},
    title = { A Short Introduction to Boosting},
    year = {1999}
}
@book{cover2006,
 author = {Cover, Thomas M. and Thomas, Joy A.},
 title = {Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing)},
 year = {2006},
 publisher = {Wiley-Interscience}
}

@article{ali2012,
author = {K. Ali and F. Fleuret and D. Hasler and P. Fua},
title = {A Real-Time Deformable Detector},
journal ={IEEE Transactions on Pattern Analysis and Machine Intelligence},
volume = {34},
number = {2},
year = {2012},
pages = {225-239}
}

@MISC{vidalTutorialSPC,
    author = {René Vidal},
    title = {A TUTORIAL ON SUBSPACE CLUSTERING},
    year = {}
}

@article{jordan2004,
  title={Learning spectral clustering},
  author={Jordan, FRBMI and Bach, F},
  journal={Advances on Neural Information Systems},
  volume={16},
  pages={305--312},
  year={2004}
}

@InProceedings{li2015,
author = {Li, Chun-Guang and Vidal, Rene},
title = {Structured Sparse Subspace Clustering: A Unified Optimization Framework},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
year = {2015}
}


@article{powell2008,
  author =       {Stephanie Powell and Vincent A. Magnotta and Hans Johnson and
                  Vamsi K. Jammalamadaka and Ronald Pierson and Nancy C.
                  Andreasen},
  title =        {Registration and Machine Learning-Based Automated Segmentation
                  of Subcortical and Cerebellar Brain Structures},
  journal =      {NeuroImage},
  volume =       39,
  number =       1,
  pages =        {238-247},
  year =         2008,
}

@Inbook{gasmi2012,
author="Gasmi, Karim
and Kharrat, Ahmed
and Messaoud, Mohamed Ben
and Abid, Mohamed",
editor="Campilho, Aur{\'e}lio
and Kamel, Mohamed",
chapter="Automated Segmentation of Brain Tumor Using Optimal Texture Features and Support Vector Machine Classifier",
title="Image Analysis and Recognition: 9th International Conference, ICIAR 2012, Aveiro, Portugal, June 25-27, 2012. Proceedings, Part II",
year="2012",
pages="230--239",
}

@article{vijayakumar2007,
  author =       {C. Vijayakumar and Gharpure Damayanti and R. Pant and C.M.
                  Sreedhar},
  title =        {Segmentation and Grading of Brain Tumors on Apparent Diffusion
                  Coefficient Images Using Self-Organizing Maps},
  journal =      {Computerized Medical Imaging and Graphics},
  volume =       31,
  number =       7,
  pages =        {473-484},
  year =         2007,
}


@Manual{eyegazetracker,
  title =        {Eye Tribe Tracker, The Eye Tribe},
  OPTkey =       {},
  OPTauthor =    {},
  OPTorganization = {},
  OPTaddress =   {https://theeyetribe.com/products/},
  OPTedition =   {},
  OPTmonth =     {},
  OPTyear =      {},
  OPTnote =      {},
  OPTannote =    {}
}



@article{zikic2014,
  author =       {D. Zikic and B. Glocker and A. Criminisi},
  title =        {Encoding Atlases By Randomized Classification Forests for
                  Efficient Multi-Atlas Label Propagation},
  journal =      {Medical Image Analysis},
  volume =       18,
  number =       8,
  pages =        {1262-1273},
  year =         2014
}

@Inbook{pinheiro2013,
author="Pinheiro, Miguel Am{\'a}vel
and Sznitman, Raphael
and Serradell, Eduard
and Kybic, Jan
and Moreno-Noguer, Francesc
and Fua, Pascal",
chapter="Active Testing Search for Point Cloud Matching",
title="International Conference on Information Processing in Medical Imaging",
year="2013",
pages="572--583",
}




@article{wang2014,
  author =       { Junqiu Wang and Yasushi Yagi},
  title =        {Many-To-Many Superpixel Matching for Robust Tracking},
  journal =      {IEEE Trans. Cybern.},
  volume =       44,
  number =       7,
  pages =        {1237-1248},
  year =         2014,
}

@INPROCEEDINGS{grundmann2010,
author={M. Grundmann and V. Kwatra and M. Han and I. Essa},
booktitle={Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on},
title={Efficient hierarchical graph-based video segmentation},
year={2010},
pages={2141-2148},
keywords={image segmentation;image sequences;graph based video segmentation;hierarchical approach;optical flow;spatiotemporal segmentation;video sequence;Image motion analysis;Iterative algorithms;Scalability;Spatiotemporal phenomena;Streaming media;Tree graphs;Video sequences},
doi={10.1109/CVPR.2010.5539893},
ISSN={1063-6919},
month={June},}

@article{felzenszwalb2004,
 author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
 title = {Efficient Graph-Based Image Segmentation},
 journal = {Int. J. Comput. Vision},
 issue_date = {September 2004},
 volume = {59},
 number = {2},
 month = sep,
 year = {2004},
 issn = {0920-5691},
 pages = {167--181},
 numpages = {15},
 url = {http://dx.doi.org/10.1023/B:VISI.0000022288.19776.77},
 doi = {10.1023/B:VISI.0000022288.19776.77},
 acmid = {981796},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {clustering, graph algorithm, image segmentation, perceptual organization},
}

@InProceedings{khosravan16,
author="Khosravan, Naji
and Celik, Haydar
and Turkbey, Baris
and Cheng, Ruida
and McCreedy, Evan
and McAuliffe, Matthew
and Bednarova, Sandra
and Jones, Elizabeth
and Chen, Xinjian
and Choyke, Peter
and Wood, Bradford
and Bagci, Ulas",
title="Gaze2Segment: A Pilot Study for Integrating Eye-Tracking Technology into Medical Image Segmentation",
booktitle="Workshop on Medical Computer Vision, Internation Conference on Medical Image Computing and Computer Aided Intervention",
year="2017",
pages="94--104",
}


@inproceedings{kumar2008,
 author = {Kumar, Manu and Klingner, Jeff and Puranik, Rohan and Winograd, Terry and Paepcke, Andreas},
 title = {Improving the Accuracy of Gaze Input for Interaction},
 booktitle = {Proceedings of the 2008 Symposium on Eye Tracking Research \&\#38; Applications},
 series = {ETRA '08},
 year = {2008},
 isbn = {978-1-59593-982-1},
 location = {Savannah, Georgia},
 pages = {65--68},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1344471.1344488},
 doi = {10.1145/1344471.1344488},
 acmid = {1344488},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {eye tracking, eye-hand coordination, fixation smoothing, focus points, gaze input, gaze-enhanced user interface design},
}

@article{hou2012,
author = {Xiaodi Hou and Jonathan Harel and Christof Koch},
title = {Image Signature: Highlighting Sparse Salient Regions},
journal ={IEEE Transactions on Pattern Analysis and Machine Intelligence},
volume = {34},
number = {1},
issn = {0162-8828},
year = {2012},
pages = {194-201},
doi = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2011.146},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
}

@INPROCEEDINGS{achanta2009,
author={R. Achanta and S. Hemami and F. Estrada and S. Susstrunk},
booktitle={Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
title={Frequency-tuned salient region detection},
year={2009},
pages={1597-1604},
keywords={edge detection;image colour analysis;image resolution;color;frequency-tuned salient region detection;full resolution saliency map;luminance;visual saliency;Biological system modeling;Biology computing;Frequency domain analysis;Frequency estimation;Image analysis;Image coding;Image segmentation;Object detection;Object recognition;Object segmentation},
doi={10.1109/CVPR.2009.5206596},
ISSN={1063-6919},
month={June},}


@ARTICLE{goferman2012,
author={S. Goferman and L. Zelnik-Manor and A. Tal},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Context-Aware Saliency Detection},
year={2012},
volume={34},
number={10},
pages={1915-1926},
keywords={Context awareness;Estimation;Feature extraction;Human factors;Image color analysis;Object recognition;Visualization;Image saliency;context aware.;visual saliency;Algorithms;Animals;Birds;Computer Graphics;Fishes;Humans;Image Processing, Computer-Assisted;Visual Perception},
doi={10.1109/TPAMI.2011.272},
ISSN={0162-8828},
month={Oct},}

@Article{lowe2004,
author="Lowe, David G.",
title="Distinctive Image Features from Scale-Invariant Keypoints",
journal="International Journal of Computer Vision",
volume="60",
number="2",
pages="91--110",
abstract="This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.",
issn="1573-1405",
doi="10.1023/B:VISI.0000029664.99615.94",
url="http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94"
}
@INPROCEEDINGS{muja2009,
    author = {Marius Muja and David G. Lowe},
    title = {Fast approximate nearest neighbors with automatic algorithm configuration},
    booktitle = {In VISAPP International Conference on Computer Vision Theory and Applications},
    year = {2009},
    pages = {331--340}
}

@INPROCEEDINGS{nebehay2013,
author={G. Nebehay and R. Pflugfelder},
booktitle={Distributed Smart Cameras (ICDSC), 2013 Seventh International Conference on},
title={TLM: Tracking-learning-matching of keypoints},
year={2013},
pages={1-6},
keywords={estimation theory;image classification;image matching;image sequences;object detection;object tracking;video signal processing;TLM;embedded devices;ensemble classifier;keypoint detection;keypoint tracking;matching stage;optic flow estimation;sliding-window approach;tracking mechanism;tracking-learning-matching;training stage;video on-the-fly;Adaptive optics;Detectors;Object tracking;Optical imaging;Robustness;Training;Videos},
doi={10.1109/ICDSC.2013.6778201},
month={Oct},}

@INPROCEEDINGS{kalal2010,
author={Z. Kalal and K. Mikolajczyk and J. Matas},
booktitle={Pattern Recognition (ICPR), 2010 20th International Conference on},
title={Forward-Backward Error: Automatic Detection of Tracking Failures},
year={2010},
pages={2756-2759},
keywords={image sequences;video signal processing;video surveillance;NCC;automatic detection;forward backward error;normalized cross correlation;tracking failures;video sequences;Measurement uncertainty;Pixel;Reliability;Target tracking;Trajectory;Video sequences;forward backward error;tracking failure detection},
doi={10.1109/ICPR.2010.675},
ISSN={1051-4651},
month={Aug},}

@INPROCEEDINGS{yu2014,
author={H. Yu and X. Qi},
booktitle={IEEE International Conference on Multimedia},
title={Unsupervised cosegmentation based on superpixel matching and Fastgrabcut},
year={2014},
pages={1-6}
}

@ARTICLE{yang2014,
author={F. Yang and H. Lu and M. H. Yang},
journal={IEEE Transactions on Image Processing},
title={Robust Superpixel Tracking},
year={2014},
volume={23},
number={4},
pages={1639-1651},
keywords={computer vision;image matching;image representation;image segmentation;maximum likelihood estimation;object tracking;appearance variation;background segmentation;image matching;image representation;maximum a posterior estimate;midlevel vision;object tracking;robust superpixel tracking;target-background confidence map;Adaptation models;Computational modeling;Object tracking;Target tracking;Training;Visualization;Visual tracking;appearance model;midlevel visual cues;superpixel},
doi={10.1109/TIP.2014.2300823},
ISSN={1057-7149},
month={April},}

@Inbook{shokoufandeh2002,
author="Shokoufandeh, Ali
and Dickinson, Sven",
editor="Khosrovshahi, Gholamreza B.
and Shokoufandeh, Ali
and Shokrollahi, Amin",
chapter="Graph-Theoretical Methods in Computer Vision",
title="Theoretical Aspects of Computer Science: Advanced Lectures",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="148--174",
isbn="978-3-540-45878-4",
doi="10.1007/3-540-45878-6_5",
url="http://dx.doi.org/10.1007/3-540-45878-6_5"
}

@INPROCEEDINGS{prokaj11,
author={J. Prokaj and M. Duchaineau and G. Medioni},
booktitle={CVPR 2011 WORKSHOPS},
title={Inferring tracklets for multi-object tracking},
year={2011},
pages={37-44},
keywords={belief networks;image sequences;object tracking;sensor fusion;video signal processing;Bayesian networks;MAP data association;data association hypotheses;multi-object tracking algorithm;tracklet-based methods;vehicle tracking task;video sequences;Approximation algorithms;Inference algorithms;Joints;Noise;Position measurement;Tracking;Velocity measurement},
doi={10.1109/CVPRW.2011.5981753},
ISSN={2160-7508},
month={June},}

@article{feng14,
title = "A novel method for combining Bayesian networks, theoretical analysis, and its applications ",
journal = "Pattern Recognition ",
volume = "47",
number = "5",
pages = "2057 - 2069",
year = "2014",
note = "",
issn = "0031-3203",
doi = "http://dx.doi.org/10.1016/j.patcog.2013.12.005",
url = "http://www.sciencedirect.com/science/article/pii/S0031320313005232",
author = "Guang Feng and Jia-Dong Zhang and Stephen Shaoyi Liao",
keywords = "Bayesian networks combination",
keywords = "Conditional independencies",
keywords = "Association degree superpose",
keywords = "Knowledge fusion "
}

@Inbook{yehezkel06,
author="Yehezkel, Raanan
and Lerner, Boaz",
editor="Yeung, Dit-Yan
and Kwok, James T.
and Fred, Ana
and Roli, Fabio
and de Ridder, Dick",
chapter="Bayesian Network Structure Learning by Recursive Autonomy Identification",
title="Structural, Syntactic, and Statistical Pattern Recognition: Joint IAPR International Workshops, SSPR 2006 and SPR 2006, Hong Kong, China, August 17-19, 2006. Proceedings",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="154--162",
isbn="978-3-540-37241-7",
doi="10.1007/11815921_16",
url="http://dx.doi.org/10.1007/11815921_16"
}

@INPROCEEDINGS{nillius06,
author={P. Nillius and J. Sullivan and S. Carlsson},
booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},
title={Multi-Target Tracking - Linking Identities using Bayesian Network Inference},
year={2006},
volume={2},
pages={2187-2194},
keywords={Bayesian methods;Computer science;Filtering;Information analysis;Information resources;Joining processes;Labeling;Robustness;Surveillance;Target tracking},
doi={10.1109/CVPR.2006.198},
ISSN={1063-6919},
month={},}

@INPROCEEDINGS{chen14,
author={X. Chen and A. Jain and L. S. Davis},
booktitle={IEEE Winter Conference on Applications of Computer Vision},
title={Object co-labeling in multiple images},
year={2014},
pages={721-728},
keywords={image recognition;image segmentation;object recognition;quadratic programming;adaptive framework;appearance consistency;context consistency;image labeling;image recognition;joint image segmentation;label propagation;multiple image annotation;object co-labeling performance;object recognition;objective function;quadratic programming solver;temporal consistency;Buildings;Cost function;Image edge detection;Image segmentation;Labeling;Silicon;Videos},
doi={10.1109/WACV.2014.6836031},
ISSN={1550-5790},
month={March},}

@article{sharon06,
  title={Hierarchy and adaptivity in segmenting visual scenes},
  author={Sharon, Eitan and Galun, Meirav and Sharon, Dahlia and Basri, Ronen and Brandt, Achi},
  journal={Nature},
  volume={442},
  number={7104},
  pages={810--813},
  year={2006},
  publisher={Nature Publishing Group}
}

@inproceedings{chen11,
  title={Piecing together the segmentation jigsaw using context},
  author={Chen, Xi and Jain, Arpit and Gupta, Abhinav and Davis, Larry S},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on},
  pages={2001--2008},
  year={2011},
  organization={IEEE}
}

@ARTICLE{benshitrit14,
author={H. B. Shitrit and J. Berclaz and F. Fleuret and P. Fua},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Multi-Commodity Network Flow for Tracking Multiple People},
year={2014},
volume={36},
number={8},
pages={1614-1627},
keywords={linear programming;network theory (graphs);object tracking;APIDIS basketball dataset;ISSIA soccer dataset;PETS09 pedestrian dataset;frame-to-frame appearance;identity switch prevention;image appearance cues;multicommodity network flow problem;multiple people tracking;world championship basketball matches;Linear programming;Optimization;Radar tracking;Real-time systems;Target tracking;Trajectory;Linear Programming;MCNF;Multi-Commodity Network Flow;Multi-object tracking;Tracklet association;layered graph;linear programming;multi-commodity network flow;tracklet association},
doi={10.1109/TPAMI.2013.210},
ISSN={0162-8828},
month={Aug},}

@INPROCEEDINGS{berclaz09,
author={J. Berclaz and F. Fleuret and P. Fua},
booktitle={Performance Evaluation of Tracking and Surveillance (PETS-Winter), 2009 Twelfth IEEE International Workshop on},
title={Multiple object tracking using flow linear programming},
year={2009},
pages={1-8},
keywords={convex programming;dynamic programming;greedy algorithms;linear programming;object detection;sampling methods;search problems;tracking;PETS 2009 data set;constrained flow optimization problem;convex problem;dynamic programming;false-positive detection;flow linear programming;greedy search;multiobject tracking;object detection;sampling;Constraint optimization;Detectors;Dynamic programming;Joining processes;Linear programming;Object detection;Positron emission tomography;Robustness;Sampling methods;Trajectory},
doi={10.1109/PETS-WINTER.2009.5399488},
month={Dec},}

@INPROCEEDINGS{zhang08,
author={Li Zhang and Yuan Li and R. Nevatia},
booktitle={Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},
title={Global data association for multi-object tracking using network flows},
year={2008},
pages={1-8},
keywords={object detection;sensor fusion;tracking;EOM;MAP;cost-flow network;explicit occlusion model;inter-object occlusions;maximum-a-posteriori data association problem;min-cost flow algorithm;multiple object tracking;public pedestrian datasets;Costs;Event detection;Intelligent robots;Intelligent systems;Iterative algorithms;Iterative methods;Linear programming;Object detection;Optimization methods;Trajectory},
doi={10.1109/CVPR.2008.4587584},
ISSN={1063-6919},
month={June},}

@article{vincent10,
 author = {Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine},
 title = {Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion},
 journal = {Journal Machine Learning Research},
 volume = {11},
 year = {2010},
 pages = {3371--3408}
}

@article{yehezkel09,
 author = {Yehezkel, Raanan and Lerner, Boaz},
 title = {Bayesian Network Structure Learning by Recursive Autonomy Identification},
 journal = {Journal Machine Learning Research},
 volume = {10},
 year = {2009},
 pages = {1527--1570}
}

@article{mairal11,
 author = {Mairal, Julien and Jenatton, Rodolphe and Obozinski, Guillaume and Bach, Francis},
 title = {Convex and Network Flow Optimization for Structured Sparsity},
 journal = {J. Mach. Learn. Res.},
 issue_date = {2/1/2011},
 volume = {12},
 month = nov,
 year = {2011},
 issn = {1532-4435},
 pages = {2681--2720},
 numpages = {40},
 url = {http://dl.acm.org/citation.cfm?id=1953048.2078191},
 acmid = {2078191},
 publisher = {JMLR.org},
}

@INPROCEEDINGS{li09,
author={Y. Li and C. Huang and R. Nevatia},
booktitle={IEE Conference on Computer Vision and Pattern Recognition},
title={Learning to associate: HybridBoosted multi-target tracker for crowded scene},
year={2009},
pages={2953-2960}
}

@article{zheng15,
  author    = {Haitian Zheng and
               Yebin Liu and
               Mengqi Ji and
               Feng Wu and
               Lu Fang},
  title     = {Learning High-level Prior with Convolutional Neural Networks for Semantic
               Segmentation},
  journal   = {CoRR},
  volume    = {abs/1511.06988},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.06988},
  timestamp = {Tue, 01 Dec 2015 19:22:34 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/ZhengLJWF15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{long14,
  author    = {Jonathan Long and
               Evan Shelhamer and
               Trevor Darrell},
  title     = {Fully Convolutional Networks for Semantic Segmentation},
  journal   = {CoRR},
  volume    = {abs/1411.4038},
  year      = {2014},
  url       = {http://arxiv.org/abs/1411.4038},
  timestamp = {Mon, 01 Dec 2014 14:32:13 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/LongSD14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@ARTICLE{berclaz11,
author={J. Berclaz and F. Fleuret and E. Turetken and P. Fua},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Multiple Object Tracking Using K-Shortest Paths Optimization},
year={2011},
volume={33},
number={9},
pages={1806-1819},
keywords={dynamic programming;graph theory;greedy algorithms;object tracking;multiple object tracking;k-shortest paths optimization;occasional detection failure;false-positive detection;dynamic programming;greedy search;constrained flow optimization;convex problem;Trajectory;Optimization;Linear programming;Object detection;Tracking;Detectors;Cameras;Data association;multiobject tracking;K-shortest paths;linear programming.},
doi={10.1109/TPAMI.2011.21},
ISSN={0162-8828},
month={Sept},}

@INPROCEEDINGS{bandhari97,
author={R. Bhandari},
booktitle={Computers and Communications, 1997. Proceedings., Second IEEE Symposium on},
title={Optimal physical diversity algorithms and survivable networks},
year={1997},
pages={433-441},
keywords={graph theory;network topology;optical fibre networks;optimisation;telecommunication network reliability;telecommunication network routing;K-disjoint paths;design;digital cross-connect systems;edges;graph;optimal algorithms;optimal network topologies;optimal physical diversity algorithms;physical diversity;physical link fail;physical link failure;physically-disjoint paths;reliability;routing;spare capacity;survivable mesh networks;survivable networks;traffic;vertices;Algorithm design and analysis;Cost function;Distributed control;Laboratories;Mesh networks;Network topology;Routing;Telecommunication network reliability;Telecommunication traffic;Traffic control},
doi={10.1109/ISCC.1997.616037},
month={Jul},}

@article {suurballe74,
author = {Suurballe, J. W.},
title = {Disjoint paths in a network},
journal = {Networks},
volume = {4},
number = {2},
pages = {125--145},
year = {1974},
}

@INPROCEEDINGS{chaudhry09,
author={R. Chaudhry and A. Ravichandran and G. Hager and R. Vidal},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
title={Histograms of oriented optical flow and Binet-Cauchy kernels on nonlinear dynamical systems for the recognition of human actions},
year={2009},
pages={1932-1939}
}

@article{mordelet14,
  title={A bagging SVM to learn from positive and unlabeled examples},
  author={Mordelet, Fantine and Vert, J-P},
  journal={Pattern Recognition Letters},
  volume={37},
  pages={201--209},
  year={2014},
  publisher={Elsevier}
}

@Article{lowe04,
author="Lowe, David G.",
title="Distinctive Image Features from Scale-Invariant Keypoints",
journal="International Journal of Computer Vision",
year="2004",
volume="60",
number="2",
pages="91--110",
abstract="This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.",
issn="1573-1405",
doi="10.1023/B:VISI.0000029664.99615.94",
url="http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94"
}
@misc{endochal,
  author = {MICCAI},
  year="2015",
  title  = {Endoscopic Vision Challenge, 2015},
  url    = {https://endovis.grand-challenge.org/}
}

@InProceedings{vandesande11,
  author       = "van de Sande, K. E. A. and Uijlings, J. R. R. and Gevers, T. and Smeulders, A. W. M.",
  title        = "Segmentation As Selective Search for Object Recognition",
  booktitle    = "IEEE International Conference on Computer Vision",
  year         = "2011",
}

@Article{dezanet2016,
author="De Zanet, Sandro
and Rudolph, Tobias
and Richa, Rogerio
and Tappeiner, Christoph
and Sznitman, Raphael",
title="Retinal slit lamp video mosaicking",
journal="International Journal of Computer Assisted Radiology and Surgery",
year="2016",
month="Jun",
day="01",
volume="11",
number="6",
pages="1035--1041",
abstract="To this day, the slit lamp remains the first tool used by an ophthalmologist to examine patient eyes. Imaging of the retina poses, however, a variety of problems, namely a shallow depth of focus, reflections from the optical system, a small field of view and non-uniform illumination. For ophthalmologists, the use of slit lamp images for documentation and analysis purposes, however, remains extremely challenging due to large image artifacts. For this reason, we propose an automatic retinal slit lamp video mosaicking, which enlarges the field of view and reduces amount of noise and reflections, thus enhancing image quality.",
issn="1861-6429",
doi="10.1007/s11548-016-1377-4",
url="https://doi.org/10.1007/s11548-016-1377-4"
}

@INPROCEEDINGS{soliman16,
author={M. Soliman and H. R. Tavakoli and J. Laaksonen},
booktitle={International Conference on Image Processing Theory, Tools and Applications},
title={Towards gaze-based video annotation},
year={2016},
pages={1-5}
}

@article{jain17,
  author    = {Suyog Dutt Jain and
               Bo Xiong and
               Kristen Grauman},
  title     = {FusionSeg: Learning to combine motion and appearance for fully automatic
               segmention of generic objects in videos},
  journal   = {ArXiv},
  volume    = {1701.05384},
  year      = {2017},
}

@article{rother04,
 author = {Rother, Carsten and Kolmogorov, Vladimir and Blake, Andrew},
 title = {"GrabCut": Interactive Foreground Extraction Using Iterated Graph Cuts},
 journal = {ACM Transactions on Graphics},
 volume = {23},
 number = {3},
 year = {2004},
 issn = {0730-0301},
 pages = {309--314},
 numpages = {6}
}

@INPROCEEDINGS{karthikeyan13,
author={S. Karthikeyan and Thuyen Ngo and M. Eckstein and B. S. Manjunath},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
title={Eye tracking assisted extraction of attentionally important objects from videos},
year={2015},
pages={3241-3250}
}

@Inbook{papadopoulos14,
author="Papadopoulos, Dim P.
and Clarke, Alasdair D. F.
and Keller, Frank
and Ferrari, Vittorio",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Training Object Class Detectors from Eye Tracking Data",
bookTitle="European Conference on Computer Vision",
year="2014",
pages="361--376"
}

@book{Chapelle2006,
abstract = {A comprehensive review of an area of machine learning that deals with the use of unlabeled data in classification problems, this text looks at state-of-the-art algorithms, applications benchmark experiments, and directions for future research.},
author = {Chapelle, Olivier and Sch{\"{o}}lkopf, Bernhard and Zien, Alexander},
pages = {508},
publisher = {MIT Press},
title = {Semi-supervised learning},
year  = {2006},
}


@Inbook{ronneberger15,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
bookTitle="Internation Conference on Medical Image Computing and Computer-Assisted Intervention",
year="2015",
pages="234--241",
publisher={NOPUBLISHER}
}

@InProceedings{lejeune17,
author="Lejeune, Laurent
and Christoudias, Mario
and Sznitman, Raphael",
title="Expected Exponential Loss for Gaze-Based Video and Volume Ground Truth Annotation",
booktitle="Workshop on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis, International Conference on Medical Image Computing and Computer Assisted Intervention",
year="2017",
pages="106--115"
}


@inproceedings{sugiyama06,
 author = {Sugiyama, Masashi},
 title = {Local Fisher Discriminant Analysis for Supervised Dimensionality Reduction},
 booktitle = {International Conference on Machine Learning},
 year = {2006},
 pages = {905--912}
}

@article{simonyan14,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal   = {ArXiv},
  volume    = {409.1556},
  year      = {2014},
}

@inproceedings{yunpeng13,
title = {Studying Relationships Between Human Gaze, Description, and Computer Vision},
booktitle = {IEEE Computer Vision and Pattern Recognition},
year      = {2013},
author    = {Yun, K. and Peng, Y. and Zelinsky, G. amd Samaras, D. and Berg, T.},
pages = {739-746}
}

@InProceedings{bearman16,
author="Bearman, Amy
and Russakovsky, Olga
and Ferrari, Vittorio
and Fei-Fei, Li",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="What's the Point: Semantic Segmentation with Point Supervision",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="549--565",
abstract="The semantic image segmentation task presents a trade-off between test time accuracy and training time annotation cost. Detailed per-pixel annotations enable training accurate models but are very time-consuming to obtain; image-level class labels are an order of magnitude cheaper but result in less accurate models. We take a natural step from image-level annotation towards stronger supervision: we ask annotators to point to an object if one exists. We incorporate this point supervision along with a novel objectness potential in the training loss function of a CNN model. Experimental results on the PASCAL VOC 2012 benchmark reveal that the combined effect of point-level supervision and objectness potential yields an improvement of                                                                                   {\$}{\$}12.9{\backslash},{\backslash}{\%}{\$}{\$}                   mIOU over image-level supervision. Further, we demonstrate that models trained with point-level supervision are more accurate than models trained with image-level, squiggle-level or full supervision given a fixed annotation budget.",
isbn="978-3-319-46478-7"
}


@article{sweeney14,
    author = {Sweeney, Elizabeth M. AND Vogelstein, Joshua T. AND Cuzzocreo, Jennifer L. AND Calabresi, Peter A. AND Reich, Daniel S. AND Crainiceanu, Ciprian M. AND Shinohara, Russell T.},
    journal = {PLOS ONE},
    title = {A Comparison of Supervised Machine Learning Algorithms and Feature Vectors for MS Lesion Segmentation Using Multimodal Structural MRI},
    year = {2014},
    volume = {9},
    pages = {1-14},
    number = {4}
}


@misc{EndoChall,
title = {{MICCAI 2017 Endoscopic Vision Challenge}},
howpublished = {http://endovis.grand-challenge.org}
}

@article{alexe12,
 author = {Alexe, Bogdan and Deselaers, Thomas and Ferrari, Vittorio},
 title = {Measuring the Objectness of Image Windows},
 journal = {IEEE Transactions Pattern Analysis Machine Intelliegence},
 volume = {34},
 number = {11},
 year = {2012},
 pages = {2189--2202}
}


@article{garcia17,
  author    = {Alberto Garcia{-}Garcia and
               Sergio Orts{-}Escolano and
               Sergiu Oprea and
               Victor Villena{-}Martinez and
               Jos{\'{e}} Garc{\'{\i}}a Rodr{\'{\i}}guez},
  title     = {A Review on Deep Learning Techniques Applied to Semantic Segmentation},
  journal   = {ArXiv},
  volume    = {1704.06857},
  year      = {2017}
  }

@incollection{lucchi12,
  title={Structured image segmentation using kernelized features},
  author={Lucchi, Aur{\'e}lien and Li, Yunpeng and Smith, Kevin and Fua, Pascal},
  booktitle={Computer Vision--ECCV 2012},
  pages={400--413},
  year={2012},
  publisher={Springer}
}


@Article{miyawaki17,
author="Miyawaki, Shinjiro
and Tawhai, Merryn H.
and Hoffman, Eric A.
and Wenzel, Sally E.
and Lin, Ching-Long",
title="Automatic construction of subject-specific human airway geometry including trifurcations based on a CT-segmented airway skeleton and surface",
journal="Biomechanics and Modeling in Mechanobiology",
year="2017",
day="01",
volume="16",
number="2",
pages="583--596",
abstract="We propose a method to construct three-dimensional airway geometric models based on airway skeletons, or centerlines (CLs). Given a CT-segmented airway skeleton and surface, the proposed CL-based method automatically constructs subject-specific models that contain anatomical information regarding branches, include bifurcations and trifurcations, and extend from the trachea to terminal bronchioles. The resulting model can be anatomically realistic with the assistance of an image-based surface; alternatively a model with an idealized skeleton and/or branch diameters is also possible. This method systematically identifies and classifies trifurcations to successfully construct the models, which also provides the number and type of trifurcations for the analysis of the airways from an anatomical point of view. We applied this method to 16 normal and 16 severe asthmatic subjects using their computed tomography images. The average distance between the surface of the model and the image-based surface was 11 {\%} of the average voxel size of the image. The four most frequent locations of trifurcations were the left upper division bronchus, left lower lobar bronchus, right upper lobar bronchus, and right intermediate bronchus. The proposed method automatically constructed accurate subject-specific three-dimensional airway geometric models that contain anatomical information regarding branches using airway skeleton, diameters, and image-based surface geometry. The proposed method can construct (i) geometry automatically for population-based studies, (ii) trifurcations to retain the original airway topology, (iii) geometry that can be used for automatic generation of computational fluid dynamics meshes, and (iv) geometry based only on a skeleton and diameters for idealized branches."
}

@article{pilch12,
author = {Matth\"{a}us Pilch and Yaroslava Wenner and Elisabeth Strohmayr and Markus Preising and Christoph Friedburg and Erdmuthe Meyer zu Bexten and Birgit Lorenz and Knut Stieger},
journal = {Biomedical Optics Express},
number = {7},
pages = {1478--1491},
title = {Automated segmentation of retinal blood vessels in spectral domain optical coherence tomography scans},
volume = {3},
month = {Jul},
year = {2012}
}

@inproceedings{seyed13,
  title={Segmentation of mitochondria in electron microscopy images using algebraic curves},
  author={Seyedhosseini, Mojtaba and Ellisman, Mark H and Tasdizen, Tolga},
  booktitle={International Symposium on Biomedical Imaging},
  pages={860--863},
  year={2013}
}

@article{tzeng17,
  author    = {Eric Tzeng and
               Judy Hoffman and
               Kate Saenko and
               Trevor Darrell},
  title     = {Adversarial Discriminative Domain Adaptation},
  journal   = {ArXiv},
  volume    = {1702.05464},
  year      = {2017},
}

@article{mavandadi12,
  title={Distributed medical image analysis and diagnosis through crowd-sourced games: a malaria case study},
  author={Mavandadi, Sam and Dimitrov, Stoyan and Feng, Steve and Yu, Frank and Sikora, Uzair and Yaglidere, Oguzhan and Padmanabhan, Swati and Nielsen, Karin and Ozcan, Aydogan},
  journal={PloS one},
  volume={7},
  number={5},
  pages={e37245},
  year={2012},
  publisher={Public Library of Science}
}

@inproceedings{menze10,
  title={A generative model for brain tumor segmentation in multi-modal images},
  author={Menze, Bjoern H and Van Leemput, Koen and Lashkari, Danial and Weber, Marc-Andr{\'e} and Ayache, Nicholas and Golland, Polina},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={151--159},
  year={2010},
  organization={Springer}
}

@inproceedings{su15,
  title={Multi-view convolutional neural networks for 3d shape recognition},
  author={Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},
  booktitle={International Conference on Computer Vision},
  pages={945--953},
  year={2015}
}

@inproceedings{ferreira12,
  title={An annotation tool for dermoscopic image segmentation},
  author={Ferreira, Pedro M and Mendon{\c{c}}a, Teresa and Rozeira, Jorge and Rocha, Paula},
  booktitle={Proceedings of the 1st International Workshop on Visual Interfaces for Ground Truth Collection in Computer Vision Applications},
  pages={5},
  year={2012},
  organization={ACM}
}

@InProceedings{roberts11,
author="Roberts, Mike
and Jeong, Won-Ki
and V{\'a}zquez-Reina, Amelio
and Unger, Markus
and Bischof, Horst
and Lichtman, Jeff
and Pfister, Hanspeter",
editor="Fichtinger, Gabor
and Martel, Anne
and Peters, Terry",
title="Neural Process Reconstruction from Sparse User Scribbles",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2011",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="621--628",
abstract="We present a novel semi-automatic method for segmenting neural processes in large, highly anisotropic EM (electron microscopy) image stacks. Our method takes advantage of sparse scribble annotations provided by the user to guide a 3D variational segmentation model, thereby allowing our method to globally optimally enforce 3D geometric constraints on the segmentation. Moreover, we leverage a novel algorithm for propagating segmentation constraints through the image stack via optimal volumetric pathways, thereby allowing our method to compute highly accurate 3D segmentations from very sparse user input. We evaluate our method by reconstructing 16 neural processes in a 1024{\texttimes}1024{\texttimes}50 nanometer-scale EM image stack of a mouse hippocampus. We demonstrate that, on average, our method is 68{\%} more accurate than previous state-of-the-art semi-automatic methods.",
isbn="978-3-642-23623-5"
}

@Article{bromiley14,
author="Bromiley, Paul A.
and Schunke, Anja C.
and Ragheb, Hossein
and Thacker, Neil A.
and Tautz, Diethard",
title="Semi-automatic landmark point annotation for geometric morphometrics",
journal="Frontiers in Zoology",
year="2014",
month="Aug",
day="27",
volume="11",
number="1",
pages="61",
abstract="In previous work, the authors described a software package for the digitisation of 3D landmarks for use in geometric morphometrics. In this paper, we describe extensions to this software that allow semi-automatic localisation of 3D landmarks, given a database of manually annotated training images. Multi-stage registration was applied to align image patches from the database to a query image, and the results from multiple database images were combined using an array-based voting scheme. The software automatically highlights points that have been located with low confidence, allowing manual correction.",
}

@article{menze09,
  title={A comparison of random forest and its Gini importance with standard chemometric methods for the feature selection and classification of spectral data},
  author={Menze, Bjoern H and Kelm, B Michael and Masuch, Ralf and Himmelreich, Uwe and Bachert, Peter and Petrich, Wolfgang and Hamprecht, Fred A},
  journal={BMC bioinformatics},
  volume={10},
  number={1},
  pages={213},
  year={2009},
  publisher={BioMed Central}
}

@incollection{guyon06,
  title={An introduction to feature extraction},
  author={Guyon, Isabelle and Elisseeff, Andr{\'e}},
  booktitle={Feature extraction},
  pages={1--25},
  year={2006},
  publisher={Springer}
}

@article{Boykov2006,
author = {Boykov, Yuri and Funka-Lea, Gareth},
journal = {International Journal of Computer Vision},
number = {2},
pages = {109--131},
title = {Graph Cuts and Efficient N-D Image Segmentation},
volume = {70},
year = {2006}
}


@inproceedings{vincent08,
 author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
 title = {Extracting and Composing Robust Features with Denoising Autoencoders},
 booktitle = {International Conference on Machine Learning},
 year = {2008},
 pages = {1096--1103},
}

@article{papadimitriou81,
  title={On the complexity of integer programming},
  author={Papadimitriou, Christos H},
  journal={Journal of the ACM (JACM)},
  volume={28},
  number={4},
  pages={765--768},
  year={1981},
  publisher={ACM}
}

@incollection{kojima89,
  title={A primal-dual interior point algorithm for linear programming},
  author={Kojima, Masakazu and Mizuno, Shinji and Yoshise, Akiko},
  booktitle={Progress in mathematical programming},
  pages={29--47},
  year={1989},
  publisher={Springer}
}

@techreport{klee70,
  title={How good is the simplex algorithm},
  author={Klee, Victor and Minty, George J},
  year={1970},
  institution={WASHINGTON UNIV SEATTLE DEPT OF MATHEMATICS}
}

@book{schrijver98,
  title={Theory of linear and integer programming},
  author={Schrijver, Alexander},
  year={1998},
  publisher={John Wiley \& Sons}
}

@article{welling05,
  title={Fisher linear discriminant analysis},
  author={Welling, Max},
  journal={Department of Computer Science, University of Toronto},
  volume={3},
  number={1},
  year={2005}
}

@article{russakovsky14,
  author    = {Olga Russakovsky and
               Jia Deng and
               Hao Su and
               Jonathan Krause and
               Sanjeev Satheesh and
               Sean Ma and
               Zhiheng Huang and
               Andrej Karpathy and
               Aditya Khosla and
               Michael S. Bernstein and
               Alexander C. Berg and
               Fei{-}Fei Li},
  title     = {ImageNet Large Scale Visual Recognition Challenge},
  journal   = {CoRR},
  volume    = {abs/1409.0575},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.0575},
  archivePrefix = {arXiv},
  eprint    = {1409.0575},
  timestamp = {Wed, 07 Jun 2017 14:41:16 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/RussakovskyDSKSMHKKBBF14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@INPROCEEDINGS{deng09,
author={J. Deng and W. Dong and R. Socher and L. J. Li and Kai Li and Li Fei-Fei},
booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
title={ImageNet: A large-scale hierarchical image database},
year={2009},
volume={},
number={},
pages={248-255},
keywords={Internet;computer vision;image resolution;image retrieval;multimedia computing;ontologies (artificial intelligence);trees (mathematics);very large databases;visual databases;ImageNet database;Internet;computer vision;image resolution;image retrieval;large-scale hierarchical image database;large-scale ontology;multimedia data;subtree;wordNet structure;Explosions;Image databases;Image retrieval;Information retrieval;Internet;Large-scale systems;Multimedia databases;Ontologies;Robustness;Spine},
doi={10.1109/CVPR.2009.5206848},
ISSN={1063-6919},
month={June},}

@article {bellman58,
    AUTHOR = {Bellman, Richard},
     TITLE = {On a routing problem},
   JOURNAL = {Quart. Appl. Math.},
  FJOURNAL = {Quarterly of Applied Mathematics},
    VOLUME = {16},
      YEAR = {1958},
     PAGES = {87--90},
      ISSN = {0033-569X},
   MRCLASS = {90.00},
  MRNUMBER = {0102435},
MRREVIEWER = {A. Charnes},
       DOI = {10.1090/qam/102435},
       URL = {https://doi.org/10.1090/qam/102435},
}

@article{dijkstra59,
 author = {Dijkstra, E. W.},
 title = {A Note on Two Problems in Connexion with Graphs},
 journal = {Numer. Math.},
 issue_date = {December  1959},
 volume = {1},
 number = {1},
 month = dec,
 year = {1959},
 issn = {0029-599X},
 pages = {269--271},
 numpages = {3},
 url = {http://dx.doi.org/10.1007/BF01386390},
 doi = {10.1007/BF01386390},
 acmid = {2722945},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
}

@article{lloyd1982,
  title={Least squares quantization in PCM},
  author={Lloyd, Stuart},
  journal={IEEE transactions on information theory},
  volume={28},
  number={2},
  pages={129--137},
  year={1982},
  publisher={IEEE}
}

@misc{sick02,
  title={The Boost Graph Library},
  author={Sick, J and Lee, LQ and Lumsdaine, A},
  year={2002},
  publisher={Addison-Wesley, Boston}
}

@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@InProceedings{dicom,
author="Gibaud, Bernard",
editor="Lemoigne, Yves
and Caner, Alessandra",
title="The DICOM Standard: A Brief Overview",
booktitle="Molecular Imaging: Computer Reconstruction and Practice",
year="2008",
publisher="Springer Netherlands",
address="Dordrecht",
pages="229--238",
abstract="The DICOM standard has now become the uncontested standard for the exchange and management of biomedical images. Everyone acknowledges its prominent role in the emergence of multi-vendor Picture Archiving and Communication Systems (PACS), and their successful integration with Hospital Information Systems and Radiology Information Systems, thanks to the Integrating the Healthcare Enterprise (IHE) initiative. We introduce here the basic concepts retained for the definition of objects and services in DICOM, with the hope that it will help the reader to find his or her way in the vast DICOM documentation available on the web.",
isbn="978-1-4020-8752-3"
}

@book{eng16,
  title={Qt5 C++ GUI programming cookbook},
  author={Eng, Lee Zhi},
  year={2016},
  publisher={Packt Publishing Ltd}
}

@Misc{eyetribe,
author =   {Sune Alstrup Johansen},
title =    {{EyeTribe},
howpublished = {\url{https://theeyetribe.com}}
}}

@article{grady06,
  title={Random walks for image segmentation},
  author={Grady, Leo},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={28},
  number={11},
  pages={1768--1783},
  year={2006},
  publisher={IEEE}
}

@article{goldberg88,
  title={A new approach to the maximum-flow problem},
  author={Goldberg, Andrew V and Tarjan, Robert E},
  journal={Journal of the ACM (JACM)},
  volume={35},
  number={4},
  pages={921--940},
  year={1988},
  publisher={ACM New York, NY, USA}
}

@article{kass88,
  title={Snakes: Active contour models},
  author={Kass, Michael and Witkin, Andrew and Terzopoulos, Demetri},
  journal={International journal of computer vision},
  volume={1},
  number={4},
  pages={321--331},
  year={1988},
  publisher={Springer}
}

@article{chan01,
  title={Active contours without edges},
  author={Chan, Tony F and Vese, Luminita A},
  journal={IEEE Transactions on image processing},
  volume={10},
  number={2},
  pages={266--277},
  year={2001},
  publisher={IEEE}
}

@article{osher88,
  title={Fronts propagating with curvature-dependent speed: algorithms based on Hamilton-Jacobi formulations},
  author={Osher, Stanley and Sethian, James A},
  journal={Journal of computational physics},
  volume={79},
  number={1},
  pages={12--49},
  year={1988},
  publisher={Elsevier}
}

@article{welch47,
  title={The generalization ofstudent's' problem when several different population variances are involved},
  author={Welch, Bernard L},
  journal={Biometrika},
  volume={34},
  number={1/2},
  pages={28--35},
  year={1947},
  publisher={JSTOR}
}

@article{xie15,
  author    = {Junyuan Xie and
               Ross B. Girshick and
               Ali Farhadi},
  title     = {Unsupervised Deep Embedding for Clustering Analysis},
  journal   = {CoRR},
  volume    = {abs/1511.06335},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.06335},
  archivePrefix = {arXiv},
  eprint    = {1511.06335},
  timestamp = {Mon, 13 Aug 2018 16:48:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/XieGF15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{chen17,
  author    = {Liang{-}Chieh Chen and
               George Papandreou and
               Florian Schroff and
               Hartwig Adam},
  title     = {Rethinking Atrous Convolution for Semantic Image Segmentation},
  journal   = {CoRR},
  volume    = {abs/1706.05587},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.05587},
  archivePrefix = {arXiv},
  eprint    = {1706.05587},
  timestamp = {Mon, 13 Aug 2018 16:48:07 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChenPSA17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{yu17,
  author    = {Fisher Yu and
               Vladlen Koltun and
               Thomas A. Funkhouser},
  title     = {Dilated Residual Networks},
  journal   = {CoRR},
  volume    = {abs/1705.09914},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.09914},
  archivePrefix = {arXiv},
  eprint    = {1705.09914},
  timestamp = {Mon, 13 Aug 2018 16:46:55 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/YuKF17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{schuurmans18,
  author    = {Mathijs Schuurmans and
               Maxim Berman and
               Matthew B. Blaschko},
  title     = {Efficient semantic image segmentation with superpixel pooling},
  journal   = {CoRR},
  volume    = {abs/1806.02705},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.02705},
  archivePrefix = {arXiv},
  eprint    = {1806.02705},
  timestamp = {Mon, 13 Aug 2018 16:45:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-02705.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{guo17,
  title={Improved deep embedded clustering with local structure preservation.},
  author={Guo, Xifeng and Gao, Long and Liu, Xinwang and Yin, Jianping},
  booktitle={IJCAI},
  pages={1753--1759},
  year={2017}
}

@techreport{settles09,
  title={Active learning literature survey},
  author={Settles, Burr},
  year={2009},
  institution={University of Wisconsin-Madison Department of Computer Sciences}
}

@article{orting19,
  title={A survey of crowdsourcing in medical image analysis},
  author={{\O}rting, Silas and Doyle, Andrew and van Hilten, Arno and Hirth, Matthias and Inel, Oana and Madan, Christopher R and Mavridis, Panagiotis and Spiers, Helen and Cheplygina, Veronika},
  journal={arXiv preprint arXiv:1902.09159},
  year={2019}
}

@inproceedings{park18,
  title={Crowd-assisted polyp annotation of virtual colonoscopy videos},
  author={Park, Ji Hwan and Nadeem, Saad and Marino, Joseph and Baker, Kevin and Barish, Matthew and Kaufman, Arie},
  booktitle={Medical Imaging 2018: Imaging Informatics for Healthcare, Research, and Applications},
  volume={10579},
  pages={105790M},
  year={2018},
  organization={International Society for Optics and Photonics}
}

@article{oliver18,
  title={Realistic evaluation of deep semi-supervised learning algorithms},
  author={Oliver, Avital and Odena, Augustus and Raffel, Colin A and Cubuk, Ekin Dogus and Goodfellow, Ian},
  journal={Advances in neural information processing systems},
  volume={31},
  pages={3235--3246},
  year={2018}
}
@inproceedings{ghafoorian17,
  title={Transfer learning for domain adaptation in mri: Application in brain lesion segmentation},
  author={Ghafoorian, Mohsen and Mehrtash, Alireza and Kapur, Tina and Karssemeijer, Nico and Marchiori, Elena and Pesteie, Mehran and Guttmann, Charles RG and de Leeuw, Frank-Erik and Tempany, Clare M and Van Ginneken, Bram and others},
  booktitle={International conference on medical image computing and computer-assisted intervention},
  pages={516--524},
  year={2017},
  organization={Springer}
}

@article{perone19,
  title={Unsupervised domain adaptation for medical imaging segmentation with self-ensembling},
  author={Perone, Christian S and Ballester, Pedro and Barros, Rodrigo C and Cohen-Adad, Julien},
  journal={NeuroImage},
  volume={194},
  pages={1--11},
  year={2019},
  publisher={Elsevier}
}

@article{li20,
  title={e-UDA: Efficient Unsupervised Domain Adaptation for Cross-Site Medical Image Segmentation},
  author={Li, Hongwei and Loehr, Timo and Wiestler, Benedikt and Zhang, Jianguo and Menze, Bjoern},
  journal={arXiv preprint arXiv:2001.09313},
  year={2020}
}

@article{xiao17,
  title={Cosegmentation for object-based building change detection from high-resolution remotely sensed images},
  author={Xiao, Pengfeng and Yuan, Min and Zhang, Xueliang and Feng, Xuezhi and Guo, Yanwen},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={55},
  number={3},
  pages={1587--1603},
  year={2017},
  publisher={IEEE}
}

@article {davinci,
	Title = {Surgical techniques: robot-assisted laparoscopic hysterectomy with the da Vinci surgical system},
	Author = {Advincula, AP},
	DOI = {10.1002/rcs.111},
	Number = {4},
	Volume = {2},
	Month = {December},
	Year = {2006},
	Journal = {The international journal of medical robotics + computer assisted surgery : MRCAS},
	ISSN = {1478-5951},
	Pages = {305—311},
	URL = {https://doi.org/10.1002/rcs.111},
}
@article{sun19,
  title={Brain tumor segmentation and survival prediction using multimodal MRI scans with deep learning},
  author={Sun, Li and Zhang, Songtao and Chen, Hang and Luo, Lin},
  journal={Frontiers in neuroscience},
  volume={13},
  pages={810},
  year={2019},
  publisher={Frontiers}
}

@inproceedings{criminisi08,
  title={Geos: Geodesic image segmentation},
  author={Criminisi, Antonio and Sharp, Toby and Blake, Andrew},
  booktitle={European Conference on Computer Vision},
  pages={99--112},
  year={2008},
  organization={Springer}
}
