\chapter{Introduction}

\label{intro}

Object segmentation and detection in video and 3D image modalities are crucial problems in medical imaging.
From brain tumors in MRI to surgical instruments in laparoscopic video sequences, supervised machine learning has provided reliable detection and segmention of structures of interest in various medical applications.
To ensure good prediction performances, a cornerstone of most recent methods and in particular to deep learning methods, is the need for vasts amounts of images and annotations in order to optimize large numbers of model parameters.

Furthermore, while video and 3D image data are increasingly available, generating
ground truth annotations still remains one of the most fundamental bottlenecks
for creating truly large training datasets.

The present thesis contributes to the problem of generating pixel-wise annotations
in a fast and intuitive manner.
In particular, we devise an annotation protocol in which the annotator is given a
video or volumetric sequence.
As the sequence unfolds, the annotator provides by means of a pointing device, a set of 2D locations that indicate where the object of interest lies.
In its most restrictive form, our annotation protocol provides a single 2D location per frame.

Past research that address this issue can be roughly divided in two categories,
where the first leverages computer vision techniques to generate segmentation masks from sparse and/or noisy annotations, while the second focuses on developping Machine Learning techniques to minimize an annotation budget.
In practice, both categories often overlap.

We now give a brief overview of both categories.

\section{Computer Vision Methods for Sparse Annotations}
Another line of research focuses on the annotation protocol itself so as to complement the above efforts.
While the most tedious protocol requires that images be manually segmented at a pixel-level, many computer-vision approaches exist to facilitate this task.

Early contributions relied on the Active Contour model \cite{kass88}, which assumes that an initial contour is given and parameterized as the nodes of a spline curve, in this context called an elastic snake.
The segmentation problem is formulated as finding the deformation of the initial snake that minimizes an energy term.
In its simplest form, the energy term is composed of a term that determines the fitting of the snake to the edges of the image, while another term controls the smoothness of the snake.
The energy is then minimized using gradient descent.
Following works alleviate the problem of robustness brought by noisy edge maps by minimizing the Mumford-Shah functional \cite{chan01}, and parameterize the contour using the level-set method \cite{osher88}.

More recently, annotations in the form of scribbles were considered, where the annotator is asked to draw crude delineations of one or several objects of interest, along with a scribble on the background.
A first method that handles such kind of annotations relies on the Random-Walk algorithm \cite{grady06}.
The segmentation problem reduces to assigning to each unlabeled pixel a random-walker. The label of the latter pixel is then determined by the finding the label for which the walker has a maximum probability of reaching first.

Relying on the same annotation requirement, the graph-cut approach \cite{Boykov2006}
minimizes an Markov Random Field energy objective that considers unary terms (a scalar on each pixel), and a pairwise term that models the similarity of neighboring pixels.
Concretely, the image or volume is represented as a region adjacency graph where each pixel is assigned a node, and edges connect adjacent pixels.
Each annotated positive pixels is connected to a source node, while annotated negatives are connected to a sink node.
The energy minimization is then performed using the min-cut/max-flow algorithm \cite{goldberg88}.
Using the same algorithm, grab-cut \cite{rother04}, further simplifies the scribble-based annotation protocol by considering bounding-boxes around the object of interest, which provide crude labels on both foreground and background in a single stroke.

\section{On the Wise Use of Annotation Budget}
The problem of scarcity of labeled data can also be posed in the following manner:
Given a limited annotation budget, i.e. when only a few hours of annotation work can be provided, how can one make the best use of it?

\gls{al} \cite{settles09} considers semi-supervised learning scenarios, where abundant unlabeled data are available.
\gls{al} algorithms select unlabeled samples that are the most informative to the \gls{ML} model, i.e. it assumes that many unlabeled samples represent redundant information to the late-stage \gls model.
In \cite{KonSznFua15}, authors devise a strategy to select unlabeled supervoxels of a 3D volume so as to segment volumes of various modalities.
The approach iteratively trains a classifier and takes its entropy as measure of uncertainty.
Combining the latter with a geometric prior, which takes into account intuitive rules on spatial coherence, they sample a batch of most uncertain samples.
The classifier is then re-trained using the newly annotated samples.

Crowd-sourcing, refers to the outsourcing of the annotation task to a high number of annotators \cite{orting19}.
Its use in the frame of medical imaging poses several limitations.
First, the difficulty of the annotation task can prohibit the effective use of crowd-sourcing, e.g with heart of breast scans \cite{orting19}.
Another limitation is the nature of the data, i.e. one usually prefers to pre-classify brain scans and ask a crowd to segment tumors that are known to exist.
Last, one must usually integrate a test-task to ensure the competence of workers, or filter-out annotations provided by ``poorly performing'' workers \cite{park18}.

\section{Semi-supervised and Transfer Learning}
\gls{ssl} combines traditional supervised learning tasks, where a fully labeled training dataset is available, with abundant unlabeled samples.
The latter, under specific conditions, can boost the performance of an ML model as trained with labeled dataset only.
The basic idea is that the ML model may acquire knowledge of the data distribution from the unlabeled set.
As pointed out by \cite{oliver18}, the implicit assumption is that both sets share similar data distributions.

\gls{tl} consists in using a \gls{ml} model trained on a similar task, but with a training set of different nature than the targeted domain, e.g. use a \gls{cnn} configured for segmenting natural objects (trees, cars, ...) to segment surgical tools.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../main"
%%% End:
