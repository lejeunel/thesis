
\subsection{Non-negative Positive-Unlabeled learning}
\label{sec:nnpu}

We first briefly introduce and formulate Non-negative Positive-Unlabeled learning~\cite{kiryo17} in the context of semantic segmentation.

Traditional supervised learning, which we denote Positive/Negative learning (PN), looks to build a model \(f_{\theta}: I \mapsto [0;1]^{W \times H}\), where \(\theta\) is a set of model parameters, \(I\) is the input image with width $W$ and height $H$. Letting \(\bm{\mathcal{I}} = \{\mathcal{I}^i\}_{i=1}^{N}\) be the set of $N$ input images corresponding to an image volume or video sequence, 
each image $\mathcal{I}^i$ is composed of pixels, $\mathcal{X}^i=\mathcal{X}_p^i \cup \mathcal{X}_n^i$, where $\mathcal{X}_p^i$ and $\mathcal{X}_n^i$ denote the positive and negative pixels, respectively. We denote $\pi^i \in (0,1)$ as the proportion of positive pixels in image $i$, and $\bm{\pi} = \{\pi^i\}_{i=1}^{N}$ as the set of such proportions over all frames. 
%To simplify the notation, we write $f_{\theta}(x) = f_{\theta}(\mathcal{I})\big|_x$ as theresponse of $f_{\theta}$ on image $\mathcal{I}$ averaged on the region defined by superpixel $x$.

Training $f$ to optimize $\theta$ can then be computed by minimizing the empirical risk of the form,
\begin{equation}
R_{pn}=\sum_{i=1}^{N} \left[ \frac{\pi^i}{|\mathcal{X}_p^i|}\sum_{x \in \mathcal{X}_p^i}\ell^+(f_{\theta}(x)) \right.+
\left. \frac{1-\pi^i}{|\mathcal{X}_n|} \sum_{x \in \mathcal{X}_n^i}\ell^-(f_{\theta}(x)) \right].
  \label{eq:pn}
\end{equation}
\noindent 
A popular choice for $\ell$ is the logistic loss, for which \(\ell^+(z)=\log(1+ e^{-z})\), \(\ell^-(z)=\log(1+e^{z})\) are the positive and negative entropy loss terms, respectively. In which case, Eq. \eqref{eq:pn} is the Balanced Cross-Entropy loss (BBCE).

Conversely, computing Eq.~\eqref{eq:pn} is infeasable in a PU settting, as neither $\bm{\pi}$ nor $\bm{\mathcal{X}}_{n}$ are known in advance. Instead, we have a set of unlabeled samples $\bm{\mathcal{X}}_{u}$ that contain both positives and negatives. As suggested in~\cite{duplessis15}, the negative risk (\ie the second term of Eq.~\eqref{eq:pn}) can however be re-written in terms of $\bm{\mathcal{X}}_{p}$ and $\bm{\mathcal{X}}_{u}$ as,

\begin{equation}
  \label{eq:nnpu}
R_{pu}=\sum_{i=1}^{N}\Biggl[ \frac{\pi^{i}}{|\mathcal{X}^{i}_{p}|}\sum_{x \in \mathcal{X}^{i}_p}\ell^+(f_{\theta}(x)) +
\Biggl( \frac{1}{|\mathcal{X}^{i}_{u}|}\sum_{x \in \mathcal{X}^{i}_u}\ell^-(f_{\theta}(x)) -
\frac{\pi^{i}}{|\mathcal{X}^{i}_{p}|}\sum_{x \in \mathcal{X}^{i}_p}\ell^-(f_{\theta}(x)) \Biggr) \Biggr].
\end{equation}
This is achieved by observing that $p(x) = \pi p(x|Y=1) + (1-\pi) p(x|Y=-1)$ and that the negative risk can be expressed as $ (1-\pi) \mathbb{E}_{X \sim p(x|Y=-1)}\left[\ell^-(f_\theta(X)) \right] =
\mathbb{E}_{X \sim p(x)}\left[\ell^-(f_\theta(X)) \right] - \pi \mathbb{E}_{X \sim p(x|Y=+1)}\left[\ell^-(f_\theta(X)) \right]$. In the case of expressive models such as Neural Networks, minimizing the objective of Eq.~\eqref{eq:nnpu} using stochastic gradient descent on mini-batches of samples tends to overfit to the training data, by driving the negative risk, (\ie the bottom term of Eq.~\eqref{eq:nnpu}) to be negative.

To circumvent this,~\cite{kiryo17} proposed to perform gradient ascent when the negative risk of a mini-batch is negative using the following negative risk,
\begin{equation}
  \label{eq:neg_risk}
R_{i}^{-}=\sum_{i=1}^N\Biggl(
 \frac{1}{|\mathcal{X}^{i}_{u}|}\sum_{x \in \mathcal{X}^{i}_u}\ell^-(f_{\theta}(x)) - 
\frac{\pi^{i}}{|\mathcal{X}^{i}_{p}|}\sum_{x \in \mathcal{X}^{i}_p}\ell^-(f_{\theta}(x)) \Biggr).
\end{equation}

Thus the complete training procedure for the PU setting with deep neural networks is described in Alg.~\ref{alg:sgdnnpu}. Specifically, when \(R_{i}^{-} < 0\), gradient ascent is performed by setting the gradient to \(-\nabla_\theta R_{i}^{-}\). 
%\algnewcommand\algorithmicforeach{\textbf{for each}}
%\algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}
\begin{algorithm}[H]
\caption{Non-negative PU learning}
\label{alg:sgdnnpu}
\begin{algorithmic}[1]
\Require{$f_\theta$: Prediction model \newline
  $\bm{\mathcal{I}}$: Set of images \newline
  $\bm{\mathcal{X}_p}, \bm{\mathcal{X}_u}$: Positive and unlabeled samples \newline
  $\bm{\pi}$: Set of class priors \newline
  $T$: Number of epochs}
\For{\texttt{epoch} $\gets 1$ to $T$}
\State Shuffle dataset into $N_{b}$ batches
    \For{$i \gets 1$ to $N_{b}$}
     \State Sample next batch to get $\mathcal{I}^i$, $\mathcal{X}_p^i$, $\mathcal{X}_u^i$, $\bm{\pi}^i$
	\State Forward pass $\mathcal{I}^i$ in $f_\theta$
	\State Compute risks as in Eq. \ref{eq:nnpu} and \ref{eq:neg_risk}
      \If{$R_{i}^{-} < 0$}
          \State Do gradient ascent along $\nabla_\theta R_{i}^{-}$
      \Else
          \State Do gradient descent along $\nabla_\theta R_{pu}$
      \EndIf
  \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

Critically, $\bm{\pi}$ plays an important role in Eq.~\eqref{eq:nnpu} and Eq.~\eqref{eq:neg_risk}. While~\cite{kiryo17} assumes that the class prior is known and constant across all the data, this is not the case in many applications, including the one at the heart of this work. In particular, the class prior here is specific to each frame of the image data available (\ie $\pi^i$) as each frame may have different numbers of positives (\eg the object may appear bigger or smaller). In addition, we show in our experimental section that setting the class prior in naive ways leads to low performance levels. In the subsequent subsection, we hence introduce a novel approach to overcome this limitation.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
