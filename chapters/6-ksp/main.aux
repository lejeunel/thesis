\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Iterative multi-path tracking}{47}{chapter.139}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction}{47}{section.140}\protected@file@percent }
\newlabel{sec:intro}{{5.1}{47}{Introduction}{section.140}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Related Works}{49}{section.141}\protected@file@percent }
\newlabel{sec:related_works}{{5.2}{49}{Related Works}{section.141}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Overview and problem formulation}{51}{section.142}\protected@file@percent }
\newlabel{sec:overview}{{5.3}{51}{Overview and problem formulation}{section.142}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Notation summary\relax }}{52}{table.caption.143}\protected@file@percent }
\newlabel{tab:notation}{{5.1}{52}{Notation summary\relax }{table.caption.143}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Transductive foreground model}{52}{section.144}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Probabilistic estimation by bagging}{53}{subsection.145}\protected@file@percent }
\newlabel{sec:foreground_model}{{5.4.1}{53}{Probabilistic estimation by bagging}{subsection.145}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Image-object specific features}{53}{subsection.146}\protected@file@percent }
\newlabel{sec:features}{{5.4.2}{53}{Image-object specific features}{subsection.146}{}}
\newlabel{eq:loss_features}{{5.1}{53}{Image-object specific features}{equation.147}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Image-object specific features. The network is tasked to reconstruct the input image $I_t$ (dark blue). By means of a loss function $\mathcal  {L}_t$, the reconstructed image, $\hat  {I}_t$ (red), is strongly penalized at 2D locations provided by means of the soft prior, $Z_t$. At test time, the features $h_t(k,l)$ are extracted by interpolating the bottom layer to the original input size. \relax }}{54}{figure.caption.149}\protected@file@percent }
\newlabel{fig:unet}{{5.1}{54}{Image-object specific features. The network is tasked to reconstruct the input image $I_t$ (dark blue). By means of a loss function $\mathcal {L}_t$, the reconstructed image, $\hat {I}_t$ (red), is strongly penalized at 2D locations provided by means of the soft prior, $Z_t$. At test time, the features $h_t(k,l)$ are extracted by interpolating the bottom layer to the original input size. \relax }{figure.caption.149}{}}
\newlabel{eq:app_vector}{{5.2}{54}{Image-object specific features}{equation.148}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Segmentation by tracking}{54}{section.150}\protected@file@percent }
\newlabel{sec:optimization}{{5.5}{54}{Segmentation by tracking}{section.150}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}MAP Formulation}{55}{subsection.151}\protected@file@percent }
\newlabel{sec:MAP}{{5.5.1}{55}{MAP Formulation}{subsection.151}{}}
\newlabel{eq:map}{{5.3}{55}{MAP Formulation}{equation.152}{}}
\newlabel{eq:map2}{{5.4}{55}{MAP Formulation}{equation.153}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Flow network formulation}{55}{subsection.154}\protected@file@percent }
\newlabel{sec:solving}{{5.5.2}{55}{Flow network formulation}{subsection.154}{}}
\newlabel{eq:int_prog}{{5.5}{56}{Flow network formulation}{equation.155}{}}
\newlabel{eq:loglikelihood}{{5.5a}{56}{Flow network formulation}{equation.156}{}}
\newlabel{eq:cap1_trans}{{5.5b}{56}{Flow network formulation}{equation.157}{}}
\newlabel{eq:conserv1}{{5.5c}{56}{Flow network formulation}{equation.158}{}}
\newlabel{eq:conserv2}{{5.5d}{56}{Flow network formulation}{equation.159}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Max-Flow graph (forward case). At each time frame $t$, a ``pseudo'' source node $\mathcal  {E}_t$ is connected via an edge with flow $f_{t}^{\mathcal  {E},n}$ (red) to tracklet $\mathcal  {T}_t^n$. Each tracklet incurs a flow $f_t^n$ (blue) to pass through a superpixel $s_t^n$. Tracklets in frame $t$ are connected to tracklets in the next frame and allow for flows $f_{t}^{m,n}$ (green). The flow $f_{t}^{n,\mathcal  {X}}$ can leave any tracklet in the network (orange).\relax }}{57}{figure.caption.160}\protected@file@percent }
\newlabel{fig:mcf}{{5.2}{57}{Max-Flow graph (forward case). At each time frame $t$, a ``pseudo'' source node $\mathcal {E}_t$ is connected via an edge with flow $f_{t}^{\mathcal {E},n}$ (red) to tracklet $\mathcal {T}_t^n$. Each tracklet incurs a flow $f_t^n$ (blue) to pass through a superpixel $s_t^n$. Tracklets in frame $t$ are connected to tracklets in the next frame and allow for flows $f_{t}^{m,n}$ (green). The flow $f_{t}^{n,\mathcal {X}}$ can leave any tracklet in the network (orange).\relax }{figure.caption.160}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}K-shortest path optimization}{58}{subsection.161}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.4}Model costs}{58}{subsection.162}\protected@file@percent }
\newlabel{sec:costs}{{5.5.4}{58}{Model costs}{subsection.162}{}}
\newlabel{eq:in_frame_cost}{{5.6}{58}{Model costs}{equation.163}{}}
\newlabel{eq:alpha}{{5.7}{59}{Model costs}{equation.164}{}}
\newlabel{eq:beta}{{5.9}{59}{Model costs}{equation.166}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.5}Iterative tracking}{59}{subsection.168}\protected@file@percent }
\newlabel{sec:iterative_ksp}{{5.5.5}{59}{Iterative tracking}{subsection.168}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces (left) Flow entrance. Superpixel boundaries are drawn in grey. All superpixels whose centroids (red circles) are contained in a circle of radius $R$ will accept entrance flow. (Right) Example of a temporal merge. Top: Path $p_l^*$ (in blue) crosses tracklets $\mathcal  {T}_t^n$ and $\mathcal  {T}_{t+1}^{m}$. Bottom: At the next iteration, the corresponding tracklets merge into a single tracklet $\mathcal  {T}_t^{l}$ with cost $C_t^n + C_{t}^{m,n} + C_{t+1}^{m}$.\relax }}{60}{figure.caption.167}\protected@file@percent }
\newlabel{fig:temporal_merge}{{5.3}{60}{(left) Flow entrance. Superpixel boundaries are drawn in grey. All superpixels whose centroids (red circles) are contained in a circle of radius $R$ will accept entrance flow. (Right) Example of a temporal merge. Top: Path $p_l^*$ (in blue) crosses tracklets $\mathcal {T}_t^n$ and $\mathcal {T}_{t+1}^{m}$. Bottom: At the next iteration, the corresponding tracklets merge into a single tracklet $\mathcal {T}_t^{l}$ with cost $C_t^n + C_{t}^{m,n} + C_{t+1}^{m}$.\relax }{figure.caption.167}{}}
\newlabel{eq:cost_transform}{{5.10}{60}{Iterative tracking}{equation.169}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Experiments}{60}{section.172}\protected@file@percent }
\newlabel{sec:experiments}{{5.6}{60}{Experiments}{section.172}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces (Top row): Original images from different datasets. Ground truth contour of the structure of interest is depicted in red and the supervised 2D locations are shown in green. (Middle row): $\rho _{t}^n$, probability estimates of the object given by our classifier after the final iteration of our approach. (Bottom row): Pixel-wise sum of binary segmentations after each iteration of the KSP optimization. Total number of iterations from left to right are: $3$, $4$, $3$, $2$.\relax }}{61}{figure.caption.170}\protected@file@percent }
\newlabel{fig:example_iter_ksp}{{5.4}{61}{(Top row): Original images from different datasets. Ground truth contour of the structure of interest is depicted in red and the supervised 2D locations are shown in green. (Middle row): $\rho _{t}^n$, probability estimates of the object given by our classifier after the final iteration of our approach. (Bottom row): Pixel-wise sum of binary segmentations after each iteration of the KSP optimization. Total number of iterations from left to right are: $3$, $4$, $3$, $2$.\relax }{figure.caption.170}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}Implementation and Computational cost}{61}{subsection.173}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.2}Selection of Parameters}{61}{subsection.175}\protected@file@percent }
\newlabel{fn:website}{{1}{61}{}{Hfootnote.174}{}}
\newlabel{alg:iter_ksp}{{4}{62}{\KSP ~Algorithm (single direction).\relax }{algorithm.171}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces {\bf  KSPTrack}~Algorithm (single direction).\relax }}{62}{algorithm.171}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Summary of the parameters used in {\bf  KSPTrack}.\relax }}{62}{table.caption.176}\protected@file@percent }
\newlabel{tab:parameters}{{5.2}{62}{Summary of the parameters used in \KSP .\relax }{table.caption.176}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.3}Datasets}{62}{subsection.177}\protected@file@percent }
\newlabel{sec:data}{{5.6.3}{62}{Datasets}{subsection.177}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.4}Generating 2D coordinate locations}{63}{subsection.179}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.5}Baselines}{63}{subsection.181}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Results}{64}{section.182}\protected@file@percent }
\newlabel{sec:results}{{5.7}{64}{Results}{section.182}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.1}Experiment 1: Accuracy of produced segmentation}{64}{subsection.183}\protected@file@percent }
\newlabel{sec:accuracy}{{5.7.1}{64}{Experiment 1: Accuracy of produced segmentation}{subsection.183}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Comparison of quantitative results on all datasets. We report the F1 score for each method on each tested sequence using 4 different 2D gaze sets. In addition, for each sequence type, we give the mean and standard deviation F1, precision (PR) and recall (RC) scores.\relax }}{66}{table.caption.184}\protected@file@percent }
\newlabel{tab:stats}{{5.3}{66}{Comparison of quantitative results on all datasets. We report the F1 score for each method on each tested sequence using 4 different 2D gaze sets. In addition, for each sequence type, we give the mean and standard deviation F1, precision (PR) and recall (RC) scores.\relax }{table.caption.184}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces ROC and Precision-Recall curves for all types of sequence. In each case, we show the performance on each sequence (in light color) and averaged over each dataset (in bold)\relax }}{67}{figure.caption.185}\protected@file@percent }
\newlabel{fig:ROC-PR}{{5.5}{67}{ROC and Precision-Recall curves for all types of sequence. In each case, we show the performance on each sequence (in light color) and averaged over each dataset (in bold)\relax }{figure.caption.185}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Accuracy of superpixel segmentation (F1 score) for each dataset type when using different proportions of positive pixels within a superpixel to define a positive superpixel. F1 scores are averaged over 4 sequences.\relax }}{67}{figure.caption.186}\protected@file@percent }
\newlabel{fig:sp_limits}{{5.6}{67}{\blue {Accuracy of superpixel segmentation (F1 score) for each dataset type when using different proportions of positive pixels within a superpixel to define a positive superpixel. F1 scores are averaged over 4 sequences.}\relax }{figure.caption.186}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.2}Experiment 2: Segmentation performance when using generated segmentations}{67}{subsection.189}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Qualitative results of compared methods on the tested datasets. (First column) Original image. Ground truth contour of structure of interest is depicted in red and the 2D location is shown in green. (Second row onward) Binary segmentation of methods: {KSPTrack }~(Proposed), {EEL}, {P-SVM}, {Gaze2Segment}, and {DL-prior}.\relax }}{68}{figure.caption.187}\protected@file@percent }
\newlabel{fig:all}{{5.7}{68}{Qualitative results of compared methods on the tested datasets. (First column) Original image. Ground truth contour of structure of interest is depicted in red and the 2D location is shown in green. (Second row onward) Binary segmentation of methods: \KSPnb ~(Proposed), \EELnb , \PSVMnb , \GSnb , and \DLnb .\relax }{figure.caption.187}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces  Example paths in the forward and backward tracking directions on a Brain sequence. The ground truth is highlighted in red. Segmented superpixels are highlighted in blue. Numbers within superpixel regions denote indices of paths. \relax }}{69}{figure.caption.188}\protected@file@percent }
\newlabel{fig:brain_paths}{{5.8}{69}{Example paths in the forward and backward tracking directions on a Brain sequence. The ground truth is highlighted in red. Segmented superpixels are highlighted in blue. Numbers within superpixel regions denote indices of paths. \relax }{figure.caption.188}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Prediction using manual or produced training annotations. For each type, the mean of the maximum F1 scores for the proposed method (KSP) and the mouse-labeled case are shown.\relax }}{69}{table.caption.190}\protected@file@percent }
\newlabel{tab:learning}{{5.4}{69}{Prediction using manual or produced training annotations. For each type, the mean of the maximum F1 scores for the proposed method (KSP) and the mouse-labeled case are shown.\relax }{table.caption.190}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Maximum F1 scores when using {KSPTrack }or manual segmentations to train a supervised CNN for pixel wise predictions.\relax }}{70}{figure.caption.191}\protected@file@percent }
\newlabel{fig:learning}{{5.9}{70}{Maximum F1 scores when using \KSPnb or manual segmentations to train a supervised CNN for pixel wise predictions.\relax }{figure.caption.191}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.3}Experiment 3: Impact of coverage ratio and supervision}{70}{subsection.192}\protected@file@percent }
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 212}}{71}{Experiment 3: Impact of coverage ratio and supervision}{figure.caption.193}{}}
\newlabel{sub@fig:sub2}{{}{71}{Experiment 3: Impact of coverage ratio and supervision}{figure.caption.193}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 217}}{71}{Experiment 3: Impact of coverage ratio and supervision}{figure.caption.193}{}}
\newlabel{sub@fig:sub1}{{}{71}{Experiment 3: Impact of coverage ratio and supervision}{figure.caption.193}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces (Left) Graphical examples of coverage ratio for a Tweezer sequence using each of the following ratios: $20$, $40$, $60$, $75$, and $90\%$. (Right) Boxplot of F1 scores with respect to coverage ratio on a Tweezer sequence. \relax }}{71}{figure.caption.193}\protected@file@percent }
\newlabel{fig:coverage}{{5.10}{71}{(Left) Graphical examples of coverage ratio for a Tweezer sequence using each of the following ratios: $20$, $40$, $60$, $75$, and $90\%$. (Right) Boxplot of F1 scores with respect to coverage ratio on a Tweezer sequence. \relax }{figure.caption.193}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Qualitative results of our approach when using different sets of supervised 2D locations. Columns 1, 3, 5, and 7 show the original image with highlighted ground truth contour in red. The 2D locations are in green. Columns 2, 4, 6, and 8 show the mean of all binary segmentations over $5$ sets of 2D locations.\relax }}{71}{figure.caption.194}\protected@file@percent }
\newlabel{fig:multigaze}{{5.11}{71}{Qualitative results of our approach when using different sets of supervised 2D locations. Columns 1, 3, 5, and 7 show the original image with highlighted ground truth contour in red. The 2D locations are in green. Columns 2, 4, 6, and 8 show the mean of all binary segmentations over $5$ sets of 2D locations.\relax }{figure.caption.194}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.4}Experiment 4: Image-Object Features}{72}{subsection.195}\protected@file@percent }
\newlabel{eq:loss_features}{{5.11}{72}{Experiment 4: Image-Object Features}{equation.196}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.5}Experiment 5: Impact of outliers and missing 2D locations}{72}{subsection.198}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces Quantitative results of {KSPTrack }with different feature used on all datasets with five sets of 2D locations per sequence. Mean and standard deviationm F1 scores are given for 2D locations sets.\relax }}{73}{table.caption.197}\protected@file@percent }
\newlabel{tab:multigaze}{{5.5}{73}{Quantitative results of \KSPnb with different feature used on all datasets with five sets of 2D locations per sequence. Mean and standard deviationm F1 scores are given for 2D locations sets.\relax }{table.caption.197}{}}
\newlabel{fig:neigh_5}{{5.12a}{73}{\relax }{figure.caption.199}{}}
\newlabel{sub@fig:neigh_5}{{a}{73}{\relax }{figure.caption.199}{}}
\newlabel{fig:neigh_10}{{5.12b}{73}{\relax }{figure.caption.199}{}}
\newlabel{sub@fig:neigh_10}{{b}{73}{\relax }{figure.caption.199}{}}
\newlabel{fig:outliers}{{5.12c}{73}{\relax }{figure.caption.199}{}}
\newlabel{sub@fig:outliers}{{c}{73}{\relax }{figure.caption.199}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces  (a and b) Example frames with outlier regions highlighted in red corresponding to distance of $5\%$ and $10\%$, respectively. (c) F1 scores with respect to the corrupted proportion of provided 2D locations. \relax }}{73}{figure.caption.199}\protected@file@percent }
\newlabel{fig:outliers_missing}{{5.12}{73}{(a and b) Example frames with outlier regions highlighted in red corresponding to distance of $5\%$ and $10\%$, respectively. (c) F1 scores with respect to the corrupted proportion of provided 2D locations. \relax }{figure.caption.199}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.8}Conclusion}{73}{section.200}\protected@file@percent }
\newlabel{sec:conclusion}{{5.8}{73}{Conclusion}{section.200}{}}
\@writefile{toc}{\contentsline {chapter}{Appendices}{75}{chapter*.201}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.A}Edge-disjoint K-shortest paths}{75}{section.202}\protected@file@percent }
\newlabel{sec:ksp}{{5.A}{75}{Edge-disjoint K-shortest paths}{section.202}{}}
\newlabel{eq:cost_transform}{{5.12}{75}{Edge-disjoint K-shortest paths}{equation.203}{}}
\newlabel{eq:cost_transform_tracklet}{{5.12a}{75}{Edge-disjoint K-shortest paths}{equation.204}{}}
\newlabel{eq:cost_transform_transition}{{5.12b}{75}{Edge-disjoint K-shortest paths}{equation.205}{}}
\newlabel{eq:cost_transform_entrance}{{5.12c}{75}{Edge-disjoint K-shortest paths}{equation.206}{}}
\newlabel{eq:cost_transform_sink}{{5.12d}{75}{Edge-disjoint K-shortest paths}{equation.207}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.A.1}{\ignorespaces Illustration of the interlacing and augmentation procedure for $K$=2. (Left) $p_0$ is the (single) shortest-path of set $P_0$. $\tilde  {p}_0$ is the shortest interlacing path obtained after inverting the direction and algebraic sign of edge costs of $P_0$. Positive and negative labels are assigned to the edges of $P_0$. (Right) The optimal set $P_1=\{ p_1^0,p_1^1 \}$ is obtained by removing the edges with negative labels from $p_0$, and adding positive labels.\relax }}{76}{figure.caption.208}\protected@file@percent }
\newlabel{fig:augment}{{5.A.1}{76}{Illustration of the interlacing and augmentation procedure for $K$=2. (Left) $p_0$ is the (single) shortest-path of set $P_0$. $\tilde {p}_0$ is the shortest interlacing path obtained after inverting the direction and algebraic sign of edge costs of $P_0$. Positive and negative labels are assigned to the edges of $P_0$. (Right) The optimal set $P_1=\{ p_1^0,p_1^1 \}$ is obtained by removing the edges with negative labels from $p_0$, and adding positive labels.\relax }{figure.caption.208}{}}
\newlabel{alg:ksp}{{5}{76}{K-shortest paths algorithm.\relax }{algorithm.209}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces K-shortest paths algorithm.\relax }}{76}{algorithm.209}\protected@file@percent }
\@setckpt{chapters/5-ksp/main}{
\setcounter{page}{77}
\setcounter{equation}{12}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{1}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{1}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{1}
\setcounter{table}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{126}
\setcounter{maxnames}{3}
\setcounter{minnames}{3}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{cbx@tempcnta}{0}
\setcounter{cbx@tempcntb}{87}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{parentequation}{12}
\setcounter{nlinenum}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{3}
\setcounter{bookmark@seq@number}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{5}
\setcounter{ALG@line}{12}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{csvinputline}{14}
\setcounter{csvrow}{12}
\setcounter{csvcol}{17}
\setcounter{@pps}{1}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{su@anzahl}{0}
\setcounter{section@level}{1}
\setcounter{algsubstate}{3}
}
